```bash
# 一级标题
## 二级标题
### 三级标题
#### 四级标题
##### 五级标题
###### 六级标题
```

```swift
//形式一
+ a
+ b
+ c
//形式二
- d
- e
- f
//形式三
* g
* h
* i
```

```cpp
//正常形式
1. abc
2. bcd
3. cde
//错序效果
2. fgh
3. ghi
5. hij
```

```cpp
//无序列表嵌套
+ 123
    + abc
    + bcd
    + cde
+ 465
+ 789
//有序列表嵌套
1. abcd
    1. abcde
    2. abcde
    3. abcde
2. bcde
3. cdef
```

```ruby
> 一级引用
>> 二级引用
>>> 三级引用
>>>> 四级引用
>>>>> 五级引用
>>>>>> 六级引用
```

~~~go
//大量代码    
```
        daliangdaima,xuyaoduohangshiyong
        daliangdaima,xuyaoduohangshiyong
        daliangdaima,xuyaoduohangshiyong
        daliangdaima,xuyaoduohangshiyong
        daliangdaima,xuyaoduohangshiyong
    ```
~~~

```undefined
//分割线
---
- - -
------
***
* * *
******
___
_ _ _
______
```

```undefined
//强调字体
*md*    
**md**
_md_   
 __md__
```

```undefined
\\
\*
\+
\-
\`
\_
```

```undefined
~~删除~~
```

---



### Java中的filter 的

#### 三个参数

ServletRequest

ServletResponse 

FilterChain

#### 生命周期

init

doFilter

destory

#### web.xml 配置

<filter>

<filter-name>

<filter-class>

<init-param>

<param-name>

<param-value>

<filter-mapping>

<filter-name>

<url-pattern>

#### 应用

编码格式的转换 和 登录过滤

---

### Maven

#### 作用

标准化的项目结构

标准化的构建流程

管理机制

#### pom.xml说明

groupId 公司或者组织的id

artifactId 项目名称

version 

dependency 依赖

parent 父项目

dependencies 项目依赖

dependency 具体的依赖

#### 生命周期

##### 标准生命周期

clean 项目的清理

default/build 项目的部署

site 项目站点文档创建处理

###### default/build 生命周期

validata 验证项目

compile

test

package

verify 检查

intall 安装，将打包的项目安装到本地

deploy 部署，拷贝工程到远程仓库有

###### clean 的生命周期

pre-clean

clean

post-clean

###### site 生命周期

pre-site

site

post-site

site-deploy

---

### Vue

使用基于 HTML 的模板语法，声明式的将 DOM 绑定到 Vue 实例数据

#### 安装

npm install 安装依赖

npm run dev 运行程序

#### 语句

v-if 条件判断

v-else else 块

v-else-if else if 块

v-for 条件循环,如果是键值对，可使用多个参数，例如v-for="(value,key) in object"

#### 属性

计算属性 computed 只有在依赖改变时，才会重新取值

监听属性 watch 用于响应数据的变化

data 的数据，变量不用引号，在 main 中是属性，在组件中是函数，好处是每个实例维护一份被返回对象的独立拷贝

#### 指令

v-html 绑定 data 中的变量，用于输出 html 代码

v-bind/: 双向绑定 data 中的变量，也可以绑定 style 和 class，例如v-bind:class=""

v-model 单向绑定 data 中的变量，表单实现双向绑定	

v-show 根据条件来展示元素

v-on/@ 对于事件的处理，例如v-on:keyup.enter=""

#### 组件

vue 组件 封装可用的代码，全局和局部组件，父组件通过 props 把数据传给子组件，子组件通过 $on 监听事件和 $emit 触发事件，传回给父组件

#### 路由

下载 npm run vue-router

##### router-link

to 当被电击是会立即把 to 的值传到 router.push(),这个值可以是一个字符串或者是描述目标位置的对象

replace 调用的是 rourer.replace() 导航后不会留下 history 记录

append 追加路径属性

tag <router-link>想要渲染成某种标签

acitve-class 链接激活时使用的 CSS 类名

event  用来触发导航事件

---



#### 后端生成文档

1. 使用AdobeAcrobatpro，设计pdf文档模板
2. 获取模板文档路径
3. HttpServletResponse 设置头，content-type 设置为 Application/pdf
4. 读取模板，对象PdfReader
5. 转换成字节流
6. 创建可操作的 pdf 模板对象，PdfStamper
7. 封装数据，AcoFields
8. 填充数据
9. 设置是否可修改
10. 关闭资源

---

### JPA

创建表

自动实现保存和删除

#### JPA Hibernate 关系

JPA 是一种规范，不是框架

Hibernate 是JPA的一种实现，是框架

#### 注解

@Entity

@Table

@Id

@GenterateValue 指定如何标识属性可以被初始化

@Transient

@Column

@TableGenerator

#### 定义JPA接口

public interface XXRepository extends JpaRepository<XX,String>{}

#### JPA关键字

And

Or

Is/Equals

Between

LessThan

LessThanEqual

GreaterThan

GreaterThanEqual

After

Before

IsNull

Like

NotLike

OrderBy

### MyBatis

#### 什么是mybatis

MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。

#### 功能框架

1. API接口层：提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用数据处理层来完成具体的数据处理。
2. 数据处理层：负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。
3. 基础支撑层：负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将他们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。

#### 优点

- 简单易学：本身就很小且简单。没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件易于学习，易于使用，通过文档和源代码，可以比较完全的掌握它的设计思路和实现。
- 灵活：mybatis不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。通过sql基本上可以实现我们不使用数据访问框架可以实现的所有功能，或许更多。
- 解除sql与程序代码的耦合：通过提供DAL层，将业务逻辑和数据访问逻辑分离，使系统的设计更清晰，更易维护，更易单元测试。sql和代码的分离，提高了可维护性。
- 提供映射标签，支持对象与数据库的orm字段关系映射
- 提供对象关系映射标签，支持对象关系组建维护
- 提供xml标签，支持编写动态sql。

#### 缺点

- 编写SQL语句时工作量很大，尤其是字段多、关联表多时，更是如此。
- SQL语句依赖于数据库，导致数据库移植性差，不能更换数据库。
- 框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。
- 二级缓存机制不佳

#### xml配置

MyBatis 的配置文件包含了影响 MyBatis 行为甚深的设置（settings）和属性（properties）信息。

##### properties

这些属性都是可外部配置且可动态替换的，既可以在典型的 Java 属性文件中配置，亦可通过 properties 元素的子元素来传递。

<properties resource="org/mybatis/example/config.properties">  

<property name="username" value="dev_user"/>  

<property name="password" value="F2Fa3!33TYyg"/> 

</properties>

如果属性在不只一个地方进行了配置，那么 MyBatis 将按照下面的顺序来加载：

因此，通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的是 properties 属性中指定的属性。

##### settings

这是 MyBatis 中极为重要的调整设置，它们会改变 MyBatis 的运行时行为。下表描述了设置中各项的意图、默认值等。

<settings>   

<setting name="cacheEnabled" value="true"/>   

<setting name="lazyLoadingEnabled" value="true"/>   

<setting name="multipleResultSetsEnabled" value="true"/>   

<setting name="useColumnLabel" value="true"/>   

<setting name="useGeneratedKeys" value="false"/>   

<setting name="autoMappingBehavior" value="PARTIAL"/>   

<setting name="defaultExecutorType" value="SIMPLE"/>   

<setting name="defaultStatementTimeout" value="25"/>   

<setting name="safeRowBoundsEnabled" value="false"/>   

<setting name="mapUnderscoreToCamelCase" value="false"/>   

<setting name="localCacheScope" value="SESSION"/>   

<setting name="jdbcTypeForNull" value="OTHER"/>   

<setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/> 

</settings>

##### typeAliases

类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余。

<typeAliases>   

<typeAlias alias="Author" type="domain.blog.Author"/>   

<typeAlias alias="Blog" type="domain.blog.Blog"/>   

<typeAlias alias="Comment" type="domain.blog.Comment"/>   

<typeAlias alias="Post" type="domain.blog.Post"/>   

<typeAlias alias="Section" type="domain.blog.Section"/>   

<typeAlias alias="Tag" type="domain.blog.Tag"/> 

</typeAliases>//为全限定名设置一个短的名字

<typeAliases>  <package name="domain.blog"/> </typeAliases> // 配置包名

@Alias("author") //注解方式

##### typeHandlers

无论是 MyBatis 在预处理语句（PreparedStatement）中设置一个参数时，还是从结果集中取出一个值时， 都会用类型处理器将获取的值以合适的方式转换成 Java 类型。重写类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。 具体做法为：实现 `org.apache.ibatis.type.TypeHandler` 接口， 或继承一个很便利的类 `org.apache.ibatis.type.BaseTypeHandler`， 然后可以选择性地将它映射到一个 JDBC 类型。

<typeHandlers>  

<typeHandler handler="org.mybatis.example.ExampleTypeHandler"/> 

</typeHandlers>

##### 处理枚举类型

若想映射枚举类型 `Enum`，则需要从 `EnumTypeHandler` 或者 `EnumOrdinalTypeHandler` 中选一个来使用。

比如说我们想存储取近似值时用到的舍入模式。默认情况下，MyBatis 会利用 `EnumTypeHandler` 来把 `Enum` 值转换成对应的名字。

注意 `EnumTypeHandler` 在某种意义上来说是比较特别的，其他的处理器只针对某个特定的类，而它不同，它会处理任意继承了 `Enum` 的类。

使用 Mapper 接口，并不对接口进行实现，底层使用动态代理来实现，接口的全限定名就是 namespace 的值，当调用接口方法时，全限定名+方法名拼接成的 key 对应的一个唯一的 MappedStatement 

##### 配置环境

MyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中， 现实情况下有多种理由需要这么做。例如，开发、测试和生产环境需要有不同的配置；或者共享相同 Schema 的多个生产数据库， 想使用相同的 SQL 映射。许多类似的用例。

不过要记住：尽管可以配置多个环境，每个 SqlSessionFactory 实例只能选择其一。

所以，如果你想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个。而如果是三个数据库，就需要三个实例，依此类推。

<environments default="development">   

<environment id="development">     

<transactionManager type="JDBC">       

<property name="..." value="..."/>     

</transactionManager>     

<dataSource type="POOLED">       

<property name="driver" value="${driver}"/>       

<property name="url" value="${url}"/>       

<property name="username" value="${username}"/>       

<property name="password" value="${password}"/>     

</dataSource>   

</environment> 

</environments>

##### 事务

<transactionManager type="MANAGED">  <property name="closeConnection" value="false"/> </transactionManager>

##### 数据源

###### UNPOLLED

这个数据源的实现只是每次被请求时打开和关闭连接。虽然一点慢，它对在及时可用连接方面没有性能要求的简单应用程序是一个很好的选择。 不同的数据库在这方面表现也是不一样的，所以对某些数据库来说使用连接池并不重要，这个配置也是理想的。

- `driver` – 这是 JDBC 驱动的 Java 类的完全限定名（并不是JDBC驱动中可能包含的数据源类）。
- `url` – 这是数据库的 JDBC URL 地址。
- `username` – 登录数据库的用户名。
- `password` – 登录数据库的密码。
- `defaultTransactionIsolationLevel` – 默认的连接事务隔离级别。

###### POLLED

这种数据源的实现利用"池"的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。 这是一种使得并发 Web 应用快速响应请求的流行处理方式。

- `poolMaximumActiveConnections` – 在任意时间可以存在的活动（也就是正在使用）连接数量，默认值：10
- `poolMaximumIdleConnections` – 任意时间可能存在的空闲连接数。
- `poolMaximumCheckoutTime` – 在被强制返回之前，池中连接被检出（checked out）时间，默认值：20000 毫秒（即 20 秒）
- `poolTimeToWait` – 这是一个底层设置，如果获取连接花费的相当长的时间，它会给连接池打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直安静的失败），默认值：20000 毫秒（即 20 秒）。
- `poolPingQuery` – 发送到数据库的侦测查询，用来检验连接是否处在正常工作秩序中并准备接受请求。默认是"NO PING QUERY SET"，这会导致多数数据库驱动失败时带有一个恰当的错误消息。
- `poolPingEnabled` – 是否启用侦测查询。若开启，也必须使用一个可执行的 SQL 语句设置 `poolPingQuery` 属性（最好是一个非常快的 SQL），默认值：false。
- `poolPingConnectionsNotUsedFor` – 配置 poolPingQuery 的使用频度。这可以被设置成匹配具体的数据库连接超时时间，来避免不必要的侦测，默认值：0（即所有连接每一时刻都被侦测 — 当然仅当 poolPingEnabled 为 true 时适用）。

###### JNDI

这个数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。

- `initial_context` – 这个属性用来在 InitialContext 中寻找上下文（即，initialContext.lookup(initial_context)）。这是个可选属性，如果忽略，那么 data_source 属性将会直接从 InitialContext 中寻找。
- `data_source` – 这是引用数据源实例位置的上下文的路径。提供了 initial_context 配置时会在其返回的上下文中进行查找，没有提供时则直接在 InitialContext 中查找。

##### 映射器

既然 MyBatis 的行为已经由上述元素配置完了，我们现在就要定义 SQL 映射语句了。但是首先我们需要告诉 MyBatis 到哪里去找到这些语句。 Java 在自动查找这方面没有提供一个很好的方法，所以最佳的方式是告诉 MyBatis 到哪里去找映射文件。你可以使用相对于类路径的资源引用， 或完全限定资源定位符（包括 `file:///` 的 URL），或类名和包名等。

<mappers>  <mapper resource="org/mybatis/builder/AuthorMapper.xml"/>  

<mapper resource="org/mybatis/builder/BlogMapper.xml"/>  

<mapper resource="org/mybatis/builder/PostMapper.xml"/> 

</mappers>

#### 映射文件

##### select

```
<select id="selectPerson" parameterType="int" resultType="hashmap">  SELECT * FROM PERSON WHERE ID = #{id} </select>    
<select #常用参数
  id="selectPerson"
  parameterType="int"
  parameterMap="deprecated"
  resultType="hashmap"
  resultMap="personResultMap"
  flushCache="false"
  useCache="true"
  timeout="10000"
  fetchSize="256"
  statementType="PREPARED"
  resultSetType="FORWARD_ONLY"> 
```



##### insert updata delete

```
<insert  id="insertAuthor"  parameterType="domain.blog.Author"  flushCache="true"  statementType="PREPARED"  keyProperty=""  keyColumn=""  useGeneratedKeys=""  timeout="20"> 
<update  id="updateAuthor"  parameterType="domain.blog.Author"  flushCache="true"  statementType="PREPARED"  timeout="20"> 
<delete  id="deleteAuthor"  parameterType="domain.blog.Author"  flushCache="true"  statementType="PREPARED"  timeout="20">
```

##### sql

这个元素可以被用来定义可重用的 SQL 代码段，可以包含在其他语句中。

<sql id="userColumns"> ${alias}.id,${alias}.username,${alias}.password </sql>

##### 参数

```
<select id="selectUsers" resultType="User">
  select id, username, password
  from users
  where id = #{id}
</select>
```

##### 字符串替换

${}这种方式接受从用户输出的内容并提供给语句中不变的字符串是不安全的，会导致潜在的 SQL 注入攻击，因此要么不允许用户输入这些字段，要么自行转义并检验。

##### ResultsMap （一张表中）

```
<!-- In mybatis-config.xml file --> 

<typeAlias type="com.someapp.model.User" alias="User"/> 

<!-- In SQL Mapping XML file --> 
<select id="selectUsers" resultType="User">  select id, username, hashedPassword  from some_table  where id = #{id} </select>
```

##### 高级结果映射 （多张表中）

<!-- Very Complex Statement --> 

```
<select id="selectBlogDetails" resultMap="detailedBlogResultMap">  
select       B.id as blog_id,       B.title as blog_title,       B.author_id as blog_author_id,       A.id as author_id,       A.username as author_username,       A.password as author_password,       A.email as author_email,       A.bio as author_bio,       A.favourite_section as author_favourite_section,       P.id as post_id,       P.blog_id as post_blog_id,       P.author_id as post_author_id,       P.created_on as post_created_on,       P.section as post_section,       P.subject as post_subject,       P.draft as draft,       P.body as post_body,       C.id as comment_id,       C.post_id as comment_post_id,       C.name as comment_name,       C.comment as comment_text,       T.id as tag_id,       T.name as tag_name  from Blog B       
left outer join Author A on B.author_id = A.id       
left outer join Post P on B.id = P.blog_id       
left outer join Comment C on P.id = C.post_id       
left outer join Post_Tag PT on PT.post_id = P.id       
left outer join Tag T on PT.tag_id = T.id  where B.id = #{id} 
</select>
```



#### 动态sql

###### if

```
<select id="findActiveBlogWithTitleLike"     resultType="Blog">  
SELECT * FROM BLOG   WHERE state = ‘ACTIVE’   
<if test="title != null">    
AND title like #{title}  
</if> 
</select>
```

##### choose when otherwise (Java 的 switch 语句，choose 为 switch，when 为 case，otherwise 则为 default。)

```
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  <choose>
    <when test="title != null">
      AND title like #{title}
    </when>
    <when test="author != null and author.name != null">
      AND author_name like #{author.name}
    </when>
    <otherwise>
      AND featured = 1
    </otherwise>
  </choose>
</select>
```

##### trim where set

where 会帮你自动修剪条件

```
<select id="findActiveBlogLike"
     resultType="Blog">
  SELECT * FROM BLOG 
  <where> 
    <if test="state != null">
         state = #{state}
    </if> 
    <if test="title != null">
        AND title like #{title}
    </if>
    <if test="author != null and author.name != null">
        AND author_name like #{author.name}
    </if>
  </where>
</select>
<trim prefix="WHERE" prefixOverrides="AND |OR ">  ...  </trim> 
```

set 元素可以被用于动态包含需要更新的列

```
<update id="updateAuthorIfNecessary">
  update Author
    <set>
      <if test="username != null">username=#{username},</if>
      <if test="password != null">password=#{password},</if>
      <if test="email != null">email=#{email},</if>
      <if test="bio != null">bio=#{bio}</if>
    </set>
  where id=#{id}
</update>
```

##### foreach

动态 SQL 的另外一个常用的必要操作是需要对一个集合进行遍历

```
<select id="selectPostIn" resultType="domain.blog.Post">
  SELECT *
  FROM POST P
  WHERE ID in
  <foreach item="item" index="index" collection="list"
      open="(" separator="," close=")">
        #{item}
  </foreach>
</select>
```

#### 目录结构

```
/my_application
  /bin
  /devlib
  /lib                <-- MyBatis *.jar文件在这里。
  /src
    /org/myapp/
      /action
      /data           <-- MyBatis配置文件在这里, 包括映射器类, XML配置, XML映射文件。
        /mybatis-config.xml
        /BlogMapper.java
        /BlogMapper.xml
      /model
      /service
      /view
    /properties       <-- 在你XML中配置的属性 文件在这里。
  /test
    /org/myapp/
      /action
      /data
      /model
      /service
      /view
    /properties
  /web
    /WEB-INF
      /web.xml
```



### 树形结构的



### 存储

设置一个 superId ,当数据是第一级树的时候，设置为空，通过一级查找二级，依次下去。

### 常用的Utils

OSUtils 负责不同的操作系统，路径的选择

TreeUtils 树形结构utils

BeanUtils 负责bean的操作

### JsonResponse

对返回值的封装，通过code 说明状态码，通过msg说明返回的信息，还有一个泛型的data,返回响应数据。

构造方法有JsonResponse()

JsonResponse( code,message);

JsonResponse(code,message,data)

静态方法success() , 返回一个code 为0，msg为空的JsonResponse 对象

静态方法success(T data),返回一个code 为0，msg为空的，值为data的JsonResponse 对象

静态方法success(String message,T data)，返回一个code为0，message ，数据是data的JsonResponse() 方法

静态方法fail(String message),返回状态码为1， message信息

静态方法fail(int code，String message)，返回状态为code，messge信息

### 用户权限控制



### 文件的导入导出

### docker



### Java基础

#### Java 中为什么只有值传递

java 中的对象采用的不是应用调用，而是值传递

#### hashCode()  和 equals

Object 中实现了 hashCode() ，hashCode() 是两个对象equals 前的操作，haCode() 的计算方法一般通过一个质数的乘法完成，比如String 的hashCode 是通过31*hash+string[i]，每个字符串有一个特定的hash，如果hash相同，他们可能equals，如果他们equals，那么他们的hash一定相同。hashCode 可以大大减小数据的之间的对比次数，如果比较两个string 是否equals 那么正常的思路就是一个个比，这样效率太差，可通过 hashCode 来先预判一下，两个string是否相等，提高效率，缩小查找的成本。两个 hashCode 值相等，这种叫 hash 冲突。

#### String StringBuilder StringBuffer

String 对象都是用 final 修饰的，内容不可变，但是指向是可以改变的

StringBuilder 是线程不安全的，通过apped 可以追加string 

StringBuffer 是线程安全的，通过append 可以追加string，所有的方法都是加了synchronized 的

#### 反射机制



---



# 1.1. Java 入门（基础概念与常识）

## 1.1.1. Java 语言有哪些特点

简单易学、支持面向对象、支持一次编译多平台使用、支持多线程、支持网络编程、取消了指针的使用，取消了多继承

可靠安全

## 1.1.2. 关于 JVM JDK 和 JRE 最详细通俗的解答

### 1.1.2.1. JVM

java virtual machine， 负责加载.class 文件，不同的系统有不同的实现。一次编译，随处执行

### 1.1.2.2. JDK 和 JRE

JDK：是java development kit ， 包含了运行时环境、编译、还有常用的基础包，如果要编写代码推荐用这个。

JRE：是java runtime environment ， 只是包含了运行时环境，如果要跑已经编译好的.class 文件可以胜任。

## 1.1.3. Oracle JDK 和 OpenJDK 的对比

Open JDK 由sun公司开放源码，由Oracle 工程师维护

## 1.1.4. Java 和 C++的区别

c++ ：带指针，支持多继承，无内存管理（手动释放）,字符串以\0结束

java：不带指针，不支持多继承，支持单继承，实现多接口，有内存管理（自动释放），java 没有结束这个概念

## 1.1.5. 什么是 Java 程序的主类 应用程序和小程序的主类有何不同

public static void main(String[] args){} ，只能有一个，不一定是public

java 小程序中，继承JApplet 和 Applet  的子类 ，必须是public

## 1.1.6. Java 应用程序与小程序之间有哪些差别

应用程序的主线程是main（）方法，小程序没有main，主要是浏览器运行init（） 和run（） 来启动

### 1.1.7. import java 和 javax 有什么区别

java 和 javax 本质上是与java 编程语言的上下文一起使用的包，api 所必须的包是Java， javax 包含java 的扩展。javax 为标注api的一部分。实际上没有区别，都是一个名字。

### 1.1.8. 为什么说 Java 语言编译与解释并存

有编译语言的特征，也有解释语言的特征。先经过编译，编译成.class 文件，然后字节码文件由java 解释器来解释执行。就像一本英文的书，先翻译成中文，然后再去阅读。

# 1.2. Java 语法

## 1.2.1. 字符型常量和字符串常量的区别

字符型是单引号，只占两个字节，相当于一个整型值

字符串是双引号，占据若干个字节，相当于一个地址（指向内存中存放的位置）

### 1.2.2. 关于注释

单行注释 // 

多行/*  */

### 1.2.3. 标识符和关键字的区别是什么

标识符：字母、数字、下划线、$, 不以数字开头

关键字：变量修饰符、程序控制、错误处理、包相关

### 1.2.4. Java中有哪些常见的关键字

|                      |          |            |          |              |            |           |        |
| -------------------- | -------- | ---------- | -------- | ------------ | ---------- | --------- | ------ |
| 访问控制             | private  | protected  | public   |              |            |           |        |
| 类，方法和变量修饰符 | abstract | class      | extends  | final        | implements | interface | native |
|                      | new      | static     | strictfp | synchronized | transient  | volatile  |        |
| 程序控制             | break    | continue   | return   | do           | while      | if        | else   |
|                      | for      | instanceof | switch   | case         | default    |           |        |
| 错误处理             | try      | catch      | throw    | throws       | finally    |           |        |
| 包相关               | import   | package    |          |              |            |           |        |
| 基本类型             | boolean  | byte       | char     | double       | float      | int       | long   |
|                      | short    | null       | true     | false        |            |           |        |
| 变量引用             | super    | this       | void     |              |            |           |        |
| 保留字               | goto     | const      |          |              |            |           |        |

### 1.2.5. 自增自减运算符

i++  i--;

### 1.2.6. continue、break、和return的区别是什么

continue 结束本次循环

break 跳出循环体

return 结束方法的运行

### 1.2.7. Java泛型了解么？什么是类型擦除？介绍一下常用的通配符

泛型：常用于集合，就是不确定数据类型，使用T 真能代替对象类型，可以让代码的灵活性和复用性得以增强，本质是参数化类型

java 中的泛型是伪泛型，java编译期间，所有的泛型信息会被擦除，这也就是所说的类型擦除，如果没有指定具体的类型，会按照Object 类型进行处理

通配符：

？ 表示不确定的 java 类型

T (type) 表示具体的一个java类型

K V (key value) 分别代表java键值中的Key Value

E (element) 代表Element

- T 只有extends一种限定方式，<T extends List>是合法的，<T super List>是不合法的
- ？有extends与super两种限定方式，即<? extends List> 与<? super List>都是合法的
- T 用于泛型类和泛型方法的定义。？用于泛型方法的调用和形参
- 对于 ？super （下界）的通配符限定泛型，我们可以读取其中的元素，但读取出来的元素会变为 Object 类型。
- 对于 ？ extends (上界)的通配符限定泛型，我们无法向里面添加元素(只可以添加null)，只能读取其中的元素。

序列化一个泛型类，然后反序列化，丧失原有的类型信息。

### 1.2.8. ==和equals的区别

Object 中的 equals 就是比较的内存地址，好多类都会重写equals（），来实现内容的比较。

而平常我们用的== 就是比较的内存地址，基本数据类型，比较时就是比较的值，而对象类型比较时，比较的是内存地址

### 1.2.9. hashCode()与 equals()

hashCode（） 从Object 中就实现了 ，是一个本地方法，一般返回一个对象的哈希码（是一个整数），减少equals 的次数。

equals（）在Object 中也有实现，他比较的是内存地址。String 类中比较的是String 的内容。

重写equals（） 时，必须重写hashCode()，字符串堆hash 进行加功31*hash+val[i]，先比较类型，和内存值，如果相等返回true，不相等分别将String 转换为 array， 然后一次比较。

hashCode 相等，equals 可能不相等；hashCode不相等，equals 一定不相等。

## 1.3. 基本数据类型

### 1.3.1. Java中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？

就是基本类型和引用类型

byte-Byte-1

short-Short-2

int -Integer-4

long-Long-8

boolean-Boolean-1

char-Charecter-2

float-Floa-4

double-Double-8



### 1.3.2. 自动装箱与拆箱

装箱：就是将基本类型转化为包装类型，Integer i= 5；,通过valueOf实现

拆箱：就是将包装类型转化为基本类型	int a = i;，通过intValue实现

### 1.3.3. 8种基本类型的包装类和常量池

常量池技术，就是在池中缓存一些数据，Byte，Short，Integer，Long，面四种包装类型都默认创建【-128,127】 的相应的缓存数据;Character 默认创建【0，127】范围的缓存数据。Boolean 直接返回 true 和 false。如果超出范围，会返回一个新的对象。（这些都是通过valueOf 方法实现的。

## 1.4. 方法（函数）

### 1.4.1. 什么是方法的返回值?返回值在类的方法里的作用是什么?

返回值，就是通过return 返回的值，可以指定为基本数据类型和对象类型。作用时返回一个结果。

### 1.4.2. 为什么 Java 中只有值传递？

是的，方法中的形参值，是实参的一个拷贝，如果是基本数据类型，那就拷贝是原来的值，如果是引用类型，那么拷贝的是引用的值（也就是地址）。形参属于局部变量，在函数结束的时候，会释放。如果通过引用类型对数据进行修改，那么原来指向的数据也会改变，比如对象和数组。

### 1.4.3. 重载和重写的区别 

重载：根据不同的参数输入，做不同的处理。参数必须不同，返回值类型可以不同，异常可以不同，访问修饰符可以不同，编译期间。

重写：是子类继承父类的相同方法，相同的代码，做出不同的反应。返回值、方法名、参数列表必须相同，异常小于等于父，访问权限大于等于父，运行期间。

### 1.4.4. 深拷贝 vs 浅拷贝

深拷贝：不光拷贝引用类型，同时引用的数据也要拷贝一份。

浅拷贝：只是拷贝引用类型。

# Java 面向对象

## 2.1. 类和对象

### 2.1.1. 面向对象和面向过程的区别

面向对象：性能差，易维护，易扩展，易复用。

面向过程：性能好，不易维护，不易扩展，不易复用。

### 2.1.2. 构造器 Constructor 是否可被 override?

可以，对不同的数据，给出不同的处理。

### 2.1.3. 在 Java 中定义一个不做事且没有参数的构造方法的作用

如果你不写构造函数的话，jvm会自动帮你生成一个没有参数的构造函数，此时创建对象就用默认生成的构造函数。如果你写了一个有参构造函数，那么编译器就不会给你无参构造，如果再用无参构造取创建对象，就会报错。同理，子继承父也是这样，一般都将无参构造写出来。

### 2.1.4. 成员变量与局部变量的区别有哪些？

成员变量：有默认值，对象销毁，值销毁，属于对象，能被访问修饰符和static、final 修饰，。

局部变量：无默认值，方法结束，值销毁，属于方法，不能被访问修饰符和static修饰。

### 2.1.5. 创建一个对象用什么运算符?对象实体与对象引用有何不同?

new ，对象实体是放在堆中的，对象引用是放在虚拟机栈中的。对象引用可以有多个，同时指向一个对象实体。

### 2.1.6. 一个类的构造方法的作用是什么? 若一个类没有声明构造方法，该程序能正确执行吗? 为什么?

创建类，可以，编译器会自动帮你创建一个默认没有参数的构造函数，你可以用这个构造函数来创建对象。

### 2.1.7. 构造方法有哪些特性？

无返回值（连void 都不可以有）

名字与类名相同

默认使用public

生成对象时，自动执行。无需调用

### 2.1.8. 在调用子类构造方法之前会先调用父类没有参数的构造方法,其目的是?

有的成员属于父类，需要父类的构造函数进行初始化， 所以需要先调用父类的构造函数，帮助子类完成初始化工作。

### 2.1.9. 对象的相等与指向他们的引用相等,两者有什么不同?

对象相等，值得时他们在堆中有各自的数据，并且他们的数据是相同的。引用相同是指，堆中的数据只有一份，两个引用同时指向这个堆中地址。

### 2.2. 面向对象三大特征

### 2.2.1. 封装

就是将对象封装成一个盒子，只对外提供，如何创建，如何一些方法来对内部的数据进行操作。

### 2.2.2. 继承

对象之间有个共性的东西，我们把他抽象出来，让后让大家去继承这个类，就是共有的属性和方法。子类用于父类的属性和方法(只是拥有)，私有的属性和方法子类无法访问。

### 2.2.3. 多态

父类的引用指向子类对象，相同的代码产生不同的结果。

## 2.3. 修饰符

### 2.3.1. 在一个静态方法内调用一个非静态成员为什么是非法的?

静态方法是属于类的，非静态方法是属于对象的。

### 2.3.2. 静态方法和实例方法有何不同

静态方法是属于类的，通过对象和类名进行访问。

实例方法是属于对象的，通过对象进行访问。

### 2.3.3. 常见关键字总结:static,final,this,super

static：修饰属性、方法，属于类

final：修饰属性、方法、类，不可修改，不可重写、不可继承

this：指代当前对象，this（）指代当前的构造函数

super：指代父类对象，super（）指代父类的构造函数

## 2.4. 接口和抽象类

### 2.4.1. 接口和抽象类的区别是什么？

接口：没有构造函数，可以有属性public static final，可以有方法，方法体为空，默认修饰是public abstract

抽象类：可以有构造方法，可以有属性，可以有普通方法，也可以有抽象方法，抽象方法没有方法体。

## 2.5. 其它重要知识点

### 2.5.1. String StringBuffer 和 StringBuilder 的区别是什么? String 为什么是不可变的?

StringBuffer：线程安全，方法中都加了synchronized

StringBuilder：线程不安全

String：中用于存储的字符数组是private final char value[],是不可变的。而StringBuffer 和StringBuilder 继承自AbstractStringBuilder，中用于存储的字符数组是char [] value,是可变的。

### 2.5.2. Object 类的常见方法总结

hashCode()// 获取哈希码

equas()//对比对象内存地址

toString()// 类名@哈希码

wait() // 三次重载

notify()// 

notifyAll()

clone()// 复制对象

finalize()// 垃圾回收

### 2.5.3. == 与 equals(重要)

==：基本数据类型比的值，引用类型，比较的是地址

equals：Object 比较的是地址。一般自己实现，比较对象中的内容

### 2.5.4. hashCode 与 equals (重要)

重写过

```
public class Person
{
    private String name;

    private int age;

    private String sex;

    Person(String name,int age,String sex){
        this.name = name;
        this.age = age;
        this.sex = sex;
    }

    @Override public boolean equals(Object obj)
    {
        if(obj instanceof Person){
            Person person = (Person)obj;
            return name.equals(person.name);
        }
        return super.equals(obj);
    }

    @Override public int hashCode()
    {
        return name.hashCode();// 只专注要比较的字段的hashCode就行
    }
}
```

hashCode 主要减少对比的次数，如果单单实现equals ，equals 返回ture ，而hashCode 可能返回false ， 违背了hashCode 和equals 的原则（equals 相同用相同的hashCode）。

### 2.5.5. Java 序列化中如果有些字段不想进行序列化，怎么办？

使用 transient 关键字修饰，阻止实例中那些用此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。transient 只能修饰变量，不能修饰类和方法。

### 2.5.6. 获取用键盘输入常用的两种方法

```
Scanner scanner = new Scanner(System.in);
String string = scanner.nextLine();
int i = scanner.nextInt();
```

```
BufferedReader bufferReader = new BufferedReader(new InputStreamReader(System.in));
String s = bufferReader.readLine();
```

# Java 核心技术

## 3.1. 集合

### 3.1.1. Collections 工具类和 Arrays 工具类常见方法总结

Collections:

reverse（List）

shffle（List）//随机排序

sort（List，Comparator）

swap（List，int，int)

rotate（List，int）

binarySearch（List,key）

max（Collection）

fill(List,Object)

frequency（List,List)

indexOfSubList(List,List)

replaceAll(List，oldVal，newVal)

同步方法不建议使用

Arrays:

sort()

binarySearch()

equals()

fill()

asList()

toString()

copyOf()

## 3.2. 异常

所有的异常都有一个共同的祖先java.lang 中的Throwable 类。Throwable 类 有两个重要的子类 Exception 和 Error。

### 3.2.1. Java 异常类层次结构图

Error：是程序无法处理的错误，大多数情况与编写的程序无关，而是java虚拟机出现了问题，例如OutOfMemoryError、VirtualMechineError、ThreadDeath。

Exception：程序本身可以处理异常,包括运行时异常和检查异常，检查异常有IOException、SQLException，运行时异常有空指针、数组下表越界、算数异常、类型转换异常。

### 3.2.2. Throwable 类常用方法

getMessage()

toString()

getLocalizedMessage()

printStackTrace()

### 3.2.3. try-catch-finally

try：负责捕获已成，一般只有一个

catch：负责处理异常，可以有多个

finally：一定执行，一般用于释放资源，有return，先将return 入栈，然后输出finally，最后返回执行return

### 3.2.4. 使用 try-with-resources 来代替try-catch-finally

try-catch-finally : 一般在 finally 中释放资源

try-with-resource：对于必须要关闭的资源，优先使用的操作。

```java
try (Scanner scanner = new Scanner(new File("test.txt"))) {
// 单个资源需要关闭
    while (scanner.hasNext()) {
        System.out.println(scanner.nextLine());
    }
} catch (FileNotFoundException fnfe) {
    fnfe.printStackTrace();
}
```

```
try (BufferedInputStream bin = new BufferedInputStream(new FileInputStream(new File("test.txt")));
             BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(new File("out.txt")))) {
             // 多个资源需要关闭，使用分号分隔
            int b;
            while ((b = bin.read()) != -1) {
                bout.write(b);
            }
        }
        catch (IOException e) {
            e.printStackTrace();
        }
```

## 3.3. 多线程

### 3.3.1. 简述线程、程序、进程的基本概念。以及他们之间关系是什么?

线程：进程的更小单位，同类型的线程共享内存空间和资源。例如同时聊天和视频。

程序：含有指令和数据的文件，被存储在磁盘，程序是静态代码

进程：程序的一次执行过程，例如qq

### 3.3.2. 线程有哪些基本状态?

新建 new 线程被构建，但还是没有调用start（）

运行 runnable 运行状态，就绪和执行两种

阻塞 blocked

等待 waiting 需要其他线程给出通知notify（） 和notifyAll（）

超时等待 time_waiting  等待指定的时间，然后自行返回

结束 terminated 执行结束，线程结束

## 3.4. 文件与 I\O 流

### 3.4.1. Java 中 IO 流分为几种?

字符流：

BufferedReader

BufferdWriter

PipedReader

PipedWriter

FileReader

FileWriter

CharArrayReader

CharArrayWriter

StringReader

StringWriter

InputStreamReader

OutputStreamWriter

字节流：

BufferedInputStream

BufferedOutputStream

PipedInputStream

PipedOutputStream

FileInputStream

FileOutputStream

DataInputStream

DataInputStream

ObjectInputStream

ObjectOutputStream

ByteArrayInputStream

ByteArrayOutputStream

SequenceInputStream

SequenceOutputStream

### 3.4.1.1. 既然有了字节流,为什么还要有字符流?

字符流由java虚拟机转换得到，问题时非常耗时和不知道编码格式会报错，干脆就提供直接操作字符的接口，方便对字符进行操作，如果是音频文件使用字节流，如果涉及到字符的话使用字符流。

### 3.4.1.2. BIO,NIO,AIO 有什么区别?

BIO：适用于连接数目小且固定的架构。阻塞io，常用的字符流和字节流都是阻塞IO，必须等文件传输完成，才能继续线程，Socket 和ServerSocket 属于这种

NIO:适用于连接数目多且链接比较短的架构。非阻塞io，在java.nio中有提供，分别使用Buffer、channel、selector 等抽象。SocketChannel 和 Socket 属于这种。	

AIO：适用于连接数目多且连接比较长（重操作）的架构。是异步IO，是基于事件和回调机制实现的。

1. # 基础

  ## 1.1. 正确使用 equals 方法

str.equals(""),容易抛出空指针异常。

经常使用"".equals(str)。

推荐使用Objects.equals(str,"");

##   1.2. 整型包装类值的比较

自动装箱，范围在-127~128之间，创建Integer对象回缓存起来，当下次出现该数值的时候，直接从缓存取出对应的Integer对象。

##   1.3. BigDecimal

###   1.3.1. BigDecimal 的用处

用于处理精确的小数点位数，浮点数比较，基本不用==来比较，也不能使用equals来判断。会产生精度丢失，推荐使用BigDecimal 来定义浮点数的值。

###   1.3.2. BigDecimal 的大小比较

```
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("2.0");
System.out.println(a.compareTo(b));// -1 表示小于，0表示等于，1表示大于
```

###   1.3.3. BigDecimal 保留几位小数

通过 setScale 方法设置保留几位小数，以及规则。

###   1.3.4. BigDecimal 的使用注意事项

为了防止精度丢失，我们使用BigDecimal（String） 构造方法或者使用BigDecimal.valueOf(double)来创建对象，而不是使用BigDecimal(double) 的方式。

2. # 集合

  ## 2.1. Arrays.asList()使用指南

  将数组转换为List 集合，返回的是java.util.Arrays 内部的一个静态类，而不是真正java.util.ArrayList，本身还是数组，如果进行add,remove,clear操作会报不支持操作异常。如果对数组进行改变，arr[0] = 1; 那么list.get(0) 也会跟着改变。

传入的参数不能是基本类型的数组，必须包装成包装类再使用，否则生的列表大小为1

  ### 2.1.4. 如何正确的将数组转换为ArrayList?

  手动实现，for

  简便方法：new ArrayList(Arrays.asList('a','b'));

  Stream :

  ```
  Integer [] myArray = {1,2,3};
  List myList = Arrays.stream(myArray).collection(Collections.toList());
  ```

  Guava :

  ```
  List<String> il = ImmutableList.of("string", "elements");  // from varargs
  List<String> il = ImmutableList.copyOf(aStringArray);      // from array
  ```

  

  ## 2.2. Collection.toArray()方法使用的坑&如何反转数组

  

  ## 2.3. 不要在 foreach 循环里进行元素的 remove/add 操作

如果要进行remove 操作，可以使用迭代器的remove ，而不是集合类的remove，如果并发操作，需要对Iterator 对象加锁。如果通过集合类的remove/ add 方法进行，迭代器会抛出同时修改异常，这就是单线程下的fail-fast。

fail-fast ：是java集合的一种错误检测机制。多线程对fail-fast 集合进行修改时，可能会抛出同时修改异常，值得注意的时，单线程情况下， 如果操作不当，同时也可能抛出同时修改异常。java.util 包下面的所有集合都是fail-fast 的，而java.util.concurrent 包下面的所有类都是fail-safe 的。

foreach 遍历报异常的根本原因：ArrayList 中有成员变量modCount 还有一个内部类expectedModCount ,一个代表实际的修改次数，一个代表期望修改的次数。foreach 删除或者添加数据都是对modCount 进行修改，而没有对expectedModCount 进行修改，不想等，抛出异常。

## 2.4for循环中进行remove 操作，出现漏删的情况

for 循环是根据索引删除的，如果删除第一个值，那么list 会重新排序，所有的元素做位移操作，后面那个被删除的值会被挪到已经删除值得索引位置，就发生了漏删。

可以从后向前进行遍历，或者直接使用迭代器，使用Stream()，

### Servlet总结

Servlet 主要负责接受用户的请求，HttpServletRequest 使用Service（）方法，也就是doPost() 和doGet() 方法做出响应的处理。通过HttpServletResponse 对请求做出响应，Servlet 的生命周期有 init() service() destory() ,一个Servlet 类只有一个实例，Servlet 需要通过注解或者配置web.xml 文件，来实现对应的映射关系。一个Servlet 可以设置多个url 访问，Servlet 并不是线程安全的。

### 阐述Servlet和CGI的区别?

CGI的不足之处:

1，需要为每个请求启动一个操作CGI程序的系统进程。如果请求频繁，这将会带来很大的开销。

2，需要重复编写处理网络协议的代码以及编码。

Servlet的优点：

1，只需要启动一个操作系统进程以及加载一个JVM，大大降低了系统的开销

2，如果多个请求需要做同样处理的时候，这时候只需要加载一个类，这也大大降低了开销

3，所有动态加载的类可以实现对网络协议以及请求解码的共享。

4，Servlet能直接和Web服务器交互，而普通的CGI程序不能。

### Servlet接口中有哪些方法及Servlet生命周期探秘

init() 执行一次

service() 每次请求都会执行

destory() 执行一次

getServletInfo()

getServeltConfig()

### get和post请求的区别

两者几乎没有什么区别，底层都是tcp链接，get 是向服务器请求数据，post 是向服务提交数据。

关于安全性：http本身就是明文协议，每个HTTP请求和返回的每个byte都会在网络上明文传播，不管是url，header还是body。想要加密，使用https

关于编码：GET和POST实际上都能用url和body。因此所谓编码确切地说应该是http中url用什么编码，body用什么编码。

什么是请求体：从HTTP协议的角度，“请求头”就是Method + URL（含querystring）+ Headers；再后边的都是请求体。

关于url的长度：GET 的长度限制，其实就是url 的长度限制（2MB）

### 什么情况下调用doGet()和doPost()

methd 标签里是get 调用doGet() , 为post 的时候调用doPost()

### 转发（Forward）和重定向（Redirect）的区别

Forward：是服务器内部转发，url还是原来的url，可以共享request 中的数据，用于用户登录

Redirect：是客户端给服务器，服务器返回客户端，客户端再去请求，再次返回，url改变，不能共享request 中的数据，用于用户注销

### 自动刷新(Refresh)

servlet 中的HttpServletResponse 对象设置Header 属性可以实现自动刷新

Response.setHeader("Refresh","5;url=https://")

### Servlet与线程安全

servlet 本身是线程不安全的，多线程的并发读写会导致数据的不同步，讲要读的属性设置为final，要写的属性使用synchronized 或者ReentrantLock，线程安全的集合，不使用实例变量

ServletContext 和ServletSession 是线程安全的

### JSP和Servlet是什么关系

jsp：是加了java 代码的html，会先生成servlet，充当视图

servlet：应用逻辑实在java中，并完全从表示层分离，充当控制器

### JSP工作原理

先生成servlet ，然后编译成.class ，后面的request，都是通过运行.class 文件来响应客户端请求。

### JSP有哪些内置对象、作用分别是什么

out 输出服务器响应的输出流对象

request

response

session 用户的会话对象

exception 

application 服务器运行环境

page jsp页面本身

pagecontext jsp上下文，常用的操作，getServletContext getServletConfig

config

注意：ServletContext 和 Application一样，ServletContext 用于servlet，application用于jsp

### Request对象的主要方法有哪些

getRequestURL()

getQueryString()

getRemoteHost()

getHeader()

getHeaders()

getHeaderNames()

getParameter()

getParameterValues()

getParameterMap()

### request.getAttribute()和 request.getParameter()有何区别

getParameter() 是从请求获取参数，通过url 或者表单提交的参数，不需要设置，是String类型

getAttribute() 是从容器中获取参数，要想获取属性，必须先setAttribute 设置属性，设置和取都是Object 类型，重定向时可以使用setAttribute（），讲request 中有用的值传给下一处理request 的servlet

### servlet 中的常用作用域：

page：指代当前页页面

request:从请求到请求结束

session:会话的有效范围，打开浏览器到关闭的过程

application:有效范围是整个应用,与servletContext 的作用范围是一样

pagecontext:jsp页面结束，都可以使用这个范围

### include指令include的行为的区别

指令：用来包含其他文件，包含的文件可以是jsp文件，html和文本文件，包含的文件就是jsp的一部分，格式如下：<%@ include file="" %>，运行前，将所有文件经编译合成一个.class 文件。

行为：用来包含静态和动态文件，独立的字节码文件，当执行到该动作才加载被包含的字节码文件

### JSP七大动作，三大指令

三大指令：page、include、taglib

七大动作：

jsp:include

jsp:useBean

jsp:setProperty

jsp:getProperty

jsp:forward

jsp:plugin

### 讲解JSP中的四种作用域

page

request

session

application

### 如何实现JSP或Servlet的单线程模式

jsp:<%page isThreadSafe="false"%>

servlet:SingleThreadModel

### Cookie和Session的的区别

cookie:永久保持，不需要服务器资源，大小收到限制，有安全风险

session:服务器记录用户的状态，

### final 关键字

修饰类，表示不可继承（所有成员方法都会被隐式的指定为final方法），修饰方法，表示不可重写，修饰属性，表示常量（基本数据类型一旦初始化，不能修改，引用类型，一旦初始化， 不能指向其他对象）

### static 关键字

修饰块，类的初始化工作（只执行一次），修饰成员变量，表示变量属于类（可以通过对象和类进行访问），修饰成员方法，表示方法属于类（只能使用静态成员方法，可以通过类和对象进行调用），静态内部类，他的创建不需要外围类的创建，她不能使用外围类的非static 方法。

### this 关键字

指代当前对象，通过this() 来调用构造函数

### super 关键字

指代父类对象，通过使用super（）来调用父类的构造函数

注意：在构造器中调用父类的super()方法时，放首行，this（）同样

### static{}静态代码块与{}非静态代码块(构造代码块)

static{}:对类进行初始化，只执行一次，一般是对static 进行赋值

{}:对对象进行初始化，没次创建对象执行一次

### 获取Class 对象的方式

TargetObject.class

对象.getClass()

class.forName("")

### 反射的一些常用api

Class xxx = 通过三种方式获取class 对象

Method[] methods = xxx.getDeclaredMethods();

Method method = xxx.getDeclaredMethod("",String.class);

method.invoke(xxx,"实参");

Field field = xxx.getDeclaredField("value");

field.setAccessible(true);

field.set(xxx,"实参");

### 反射的优缺点

运行时加载，灵活，动态类加载

性能差，安全差

## 反编译

### 自动拆装箱

装箱，使用valueOf()，拆箱，使用xxxValue()

### foreach

数组使用for，集合使用迭代器（使用foreach，进行remove，会出现问题）

### Array.asList

传入的参数不能是基本类型的数组，必须包装成包装类再使用，否则生的列表大小为1（传入基本类型数组，会被转换成二维数组）

 将数组转换为List 集合，返回的是java.util.Arrays 内部的一个静态类，而不是真正java.util.ArrayList，本身还是数组，如果进行add,remove,clear操作会报不支持操作异常。如果对数组进行改变，arr[0] = 1; 那么list.get(0) 也会跟着改变。

### 注解

public @interface Foo 会被转换成 public interface Foo extends Annotation

属性String[] value(); 被转换成抽象方法 public abstract String[] value();

## Java性能问题

### jstack

堆栈分析

### jstat

运行的实施状况

### jmap

查看堆内存的初始化信息以及堆内存



## 1.1. 集合概述

![image-20200812213612336](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812213612336.png)

带hash 的插入顺序无序，link 的插入有序

### 1.1.2. 说说 List,Set,Map 三者的区别？

List ：元素有序，可重复

Set：元素无序，不可重复

Map:由键值对构成，key无序，不可重复，value无序，可重复

### 1.1.3. 集合框架底层数据结构总结

List:ArrayList 底层是数组，Vector 底层数组，LinkedList,双向链表

Set:HashSet 底层是HashMap,LinkedHashSet 底层是LinkedHashMap 来实现的，TreeSet,红黑树

Map:HashMap 数组+链表（链表长度大于8，转为红黑树），LinkedListMap 数组和双向链表（红黑树），Hashtable 数组和双向链表，TreeMap 红黑树

### 1.1.5. 为什么要使用集合？

数组：长度固定，类型相同

集合：长度不固定，不同类型

### 1.1.6.2. 迭代器 Iterator 有啥用？

主要用来遍历集合，特点是更加安全，通过foreach 遍历集合，底层就是用的iterator，可以确保遍历集合时，做出修改，会报同时修改异常，直接通过 集合对象的iterator() 方法进行转换。（map 使用 map.entrySet().iterator()）

### 1.1.7. 有哪些集合是线程不安全的？怎么解决呢？

通过线程安全的集合使用，在java.util.concurrent 包下，

ConcurrentHashMap 代替HashMap

CopyOnWriteArrayList 线程安全的ArrayList

ConcurrentLinkedQueue 线程安全的队列

BlockingQueue 阻塞队列

ConcurrentSkipListMap 跳表

### 1.2.1. Arraylist 和 Vector 和LinkedList的区别?

ArrayList:线程不安全，底层是数组，用于频繁的查找，支持随机访问

Vector:线程安全，底层是数组

ArrayList：线程不安全，使用的双向链表，用于频繁的删除和插入，不支持随机访问

### 1.2.2.2. RandomAccess 接口

是一个标识接口，标识这个接口的类具有随机访问的功能。在binarySearch 方法中，如果传入的List 是RandomAccess 的子类，调用indexedBinarySearch()，如果不是，那么调用 iteratorBinarySearch()，只有底层是数组才能实现 RandomAccess 

### 1.2.3. ArrayList 的扩容机制

使用无参构造函数，是一个空数组，第一次add,默认长度是10，也可以通过构造函数自己设定数组的长度，当add时，长度大于现在的数组长度，会进行扩容 int newCapacity = oldCapacity + (oldCapacity >> 1)，相当于每次会变成原来的1.5倍。

### 常用的长度方法和属性

length 针对于数组，是属性

length() 针对于字符串，是方法

size() 针对于集合，是方法

### System.arrayCopy 和 Arrays.copyOf()

System.arraycopy（源数组，起始位置，目标位置，目标数组，起始位置，复制的数量），源和目标都要提供

Arrays.copyOf （源数组，长度，类型），只提供源，返回目标，底层用的是 System.arraycopy

### 1.3.1. comparable 和 Comparator 的区别

comparable：接口，来自java.lang，有一个方法compareTo(Object obj)

comparator：接口，来自java.utils，有一个方法compare(Object obj1,Object obj2)

### 1.3.1.1. Comparator 定制排序

Arrays.sort(数组，comparator) // 通过实现comparator 来实现排序

Collections.sort(数组，comparator)// 通过实现comparator 来实现排序

普通的类通过实现 comparable接口，重写compareTo 方法来排序

### 1.3.3. 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同

HashSet 底层是HashMap，不重复，无顺序

LinkedHashSet 底层是LinkedHashMap，不重复，按顺数加入

TreeSet,红黑树，不重复，从小到大排序

### 1.4.1. HashMap 和 Hashtable 的区别

HashMap:线程不安全，性能好，默认容量是16，每次扩容变成两倍，构造函数带参数，按照2的幂次方分配空间

Hashtable：线程安全，表锁，性能差，默认容量是11，每次扩容2N+1，构造函数带参数，按照给定参数分配空间

### 1.4.2. HashMap 、TreeMap和 HashSet 区别

HashMap ：实现map接口，存储键值对，使用put，使用key 计算hashcode

HashSet ：实现set接口，存储对象，使用add，使用对象计算hashcode

TreeMap：相比于`HashMap`来说 `TreeMap` 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。

### 1.4.4. HashSet 如何检查重复

如果存入的对象没有实现 hashcode（）和equals（） 方法，那么通过内存地址的比较去重，如果实现了hashcode（）和equals（）方法，那么根据属性或者相关的比较，进行去重。

### 1.4.5. HashMap 的底层实现

数组跟链表，默认长度是16，数组扩容采用的是2的n次幂，如果链表的长度小于8，使用链表，如果链表的长度大于8，先判定数组的长度小于64不，小于那么先扩容数组，如果大于，那么将链表转换为红黑树。

### 1.4.6. HashMap 的长度为什么是 2 的幂次方

减少碰撞，Hash 值的范围值-2147483648 到 2147483647，先取模，然后才能使用，把数据均匀分配使用，下标计算方法hash&（n-1），hash%length == hash&（n-1）的前提条件是n 为 2的n次幂。

### 1.4.7. HashMap 多线程操作导致死循环问题

并发的情况下，Rehash会造成元素之间形成循环链表，多线程不推荐使用

### 1.4.8. HashMap 有哪几种常见的遍历方式?

map.entrySet().Iterator()

map.keySet().Iterator()

map.keySet()

map.entrySet()

map.foreach()

map,entrySet().stream.forEach()

### 1.4.9. ConcurrentHashMap 和 Hashtable 的区别

ConcurrentHashMap : node数组跟链表红黑树实现，并发使用synchronized 和cas 实现（synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发）

Hashtable :底层使用数组跟链，用synchronize保证安全，

## 1.5. Collections 工具类

### 1.5.1. 常用操作操作

排序

```
void reverse(List list)//反转
void shuffle(List list)//随机排序
void sort(List list)//按自然排序的升序排序
void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑
void swap(List list, int i , int j)//交换两个索引位置的元素
void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面
```

查找替换

```
int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的
int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)
int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)
void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素。
int frequency(Collection c, Object o)//统计元素出现次数
int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target).
boolean replaceAll(List list, Object oldVal, Object newVal), 用新元素替换旧元素
```

同步控制（效率低下， 不建议使用）

```
synchronizedCollection(Collection<T>  c) //返回指定 collection 支持的同步（线程安全的）collection。
synchronizedList(List<T> list)//返回指定列表支持的同步（线程安全的）List。
synchronizedMap(Map<K,V> m) //返回由指定映射支持的同步（线程安全的）Map。
synchronizedSet(Set<T> s) //返回指定 set 支持的同步（线程安全的）set。
```



### 1.6.1. 什么是快速失败(fail-fast)？

是java集合的错误检测机制，当使用迭代器遍历的时候，我们在多线程下操作非安全的结合类会触发快速失败，常抛出的异常同时修改异常，单线程下，通过foreach遍历数组时，修改集合的内容也会触发快速失败机制。

本质原因是modeCount 和exceptedModCount 的值不一致导致的。

### 1.6.2. 什么是安全失败(fail-safe)呢？

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历，不会报同时修改异常。

### 1.6.3. Arrays.asList 避坑

Arrays.asList() 将数组转换成集合，底层还是数组，数组变，集合跟着变

Arrays.asList()中的参数必须是对象数组，不能是基本类型，否则 集合的长度为1（当传入一个原生数据类型数组时，`Arrays.asList()` 的真正得到的参数就不是数组中的元素，而是数组对象本身，一个地址，此时 List 的唯一元素就是这个数组。）

Arrays.asList() 返回的集合并不是ArrayList，而是一个内部类，使用add/remove等方法，报不支持修改

1. # 什么是线程和进程?

  进程：程序的一次执行过程，运行程序的基本单位，程序运行时，jvm启动进程，进程相互独立，开销大，有利于资源的管理和保护

  线程：进程的更小执行单位，共享堆和方法区的资源，自己的本地方法栈、程序计数器、虚拟栈，开销小，不利于资源的管理和保护

##   2.2. 程序计数器为什么是私有的?

作用：字节码通过改变程序计数器来以此读取指令，实现代码的流程控制，多线程下，程序计数器用于记录当前线程的执行位置（上下文切换）。

注意：native 方法 程序计数器是undefined地址，java代码时才是下一条指令的地址。

##   2.3. 虚拟机栈和本地方法栈为什么是私有的?

java 在执行方法的同时会创建一个栈帧用来存储局部变量表、常量池引用等信息，因为保证局部变量不被其他线程访问，所以是私有的

##   2.4. 一句话简单了解堆和方法区

堆：数组和对象

方法区：类信息，常量、静态变量、编译器编译后的代码数据

## 3.1说说并发与并行的区别?

并发：时间段内，多任务都在执行

并行：单位时间内，多任务同时执行

## 4.1为什么要使用多线程呢?

计算机底层：线程是轻量级的进程，消耗的资源少，线程间切换和调度成本小，多核的cpu时代代表，多个线程可以同时运行，

互联网趋势：千万级的并发量，利用线程机制可以提高并发量

带来的问题：死锁、内存泄漏、线程不安全

## 5.1说说线程的生命周期和状态?

new:线程被构建，还没有start（）

runnable：running（运行） 和ready（就绪），调用start（）方法开始后，先进入就绪状态，获取时间片进入到running 状态

blocked：阻塞状态，在没有获取到锁的情况下（阻塞）

waiting：进入线程等待，当前线程需要其他线程的通知，相当于方法wait（）

time_waiting:在指定的时间自行返回，相当于方法wait（millis）或者sleep（millis）

terminated:表示线程执行完毕，run（）方法结束

## 6.1什么是上下文切换?

每个cpu核心只能被一个线程使用，时间片结束，线程切换，线程切换的过程就叫上下文切换，也就是任务从保存到再加载的过程就是一次上下文切换

## 7.1. 认识线程死锁

多个线程同时被阻塞，他们其中一个等待某个资源被释放，由于线程被无限期的阻塞，程序不能 正常终止，A持有资源2，B持有资源1，都想申请对方的资源，就会进入死锁

##  7.2. 如何避免线程死锁?

破坏互斥条件：本身就是让线程互斥，没办法破坏

破坏请求和保持条件： 一次申请所有的资源

破坏不剥夺：申请不到，就释放

破坏循环等待：按照顺序申请资源（上述的，AB持有资源，改为先申请资源1，然后再申请资源2）

## 8.1说说 sleep() 方法和 wait() 方法区别和共同点?

sleep（）:持有锁，用于暂停执行，会自动苏醒

wait（）：释放锁，用于线程间通信，需要别的线程进行通知

wait（）和wait（time)：不带参数需要别的线程通知叫醒，带参数则是到时间后苏醒。

## 8.2为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

start（）：启动线程，线程进入就绪状态

run（）：类下的一个普通方法，在main 线程下的执行



## 1.1.synchronized 关键字

解决并发问题的一种简单方式，只需要给方法、代码块加上关键字就行，从关键字的地方进行加锁，执行完成锁释放，jvm会自动实现.synchronized 修饰方法时锁定的是调用该方法的对象。它并不能使调用该方法的多个对象在执行顺序上互斥。静态方法是只要是该类对象都是同一把锁，锁定的是类的字节码文件（只有一份）。尽量不要给包装类型和String 类型加锁,字符串常量有缓存功能。

## 1.2. 双重检验锁实现单例模式

```
public static Singleton{
	private volatile staic Singleton uniqueInstance;
	private Singleton(){}
	public static Singleton getUniqueInstance(){
		if(uniqueInstance ==null){
			sychronize(Single.class){
				if(uniqueInstance ==null){
					uniqueInstance = new Singleton();
				}
			}
		}
		return uniqueInstance;
	}
}
```

## 1.3. 讲一下 synchronized 关键字的底层原理

synchronized 修饰代码块:翻译成字节码对应的式monitorenter 和 monitorexit 指令,monitorenter 代表指令开始的地方,monitorexit 代表指令结束的地方.synchronized 修饰方法:翻译成字节码对应的是一个标识ACC_SYNCHRONIZED.

## 1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化(虚拟机层面)

偏向锁:为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗,偏向锁的“偏”就是偏心的偏，它的意思是会偏向于第一个获得它的线程，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步

轻量级锁:它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作.如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作.

自旋锁:一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。让后面来的请求获取锁的线程等待一会而不被挂起.(调用者一直循环,查看自旋锁的保持者是否已经释放了锁),默认自旋十次,就应该挂起线程

消除锁:如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。

锁粗化:推荐将同步块的作用范围限制得尽量小

## 1.5. 谈谈 synchronized和ReentrantLock 的区别

synchronized:可重入锁(自己的内部还可以获取锁,不可重入再次获取的化会造成死锁,每次获取锁的计数器增加1,0代表锁释放),依赖于jvm,有异常会释放锁

ReentrantLock:可重入锁(自己的内部还可以获取锁,不可重入再次获取的化会造成死锁,每次获取锁的计数器增加1,0代表锁释放),依赖于api,高级功能(等待可中断,实现公平锁,可选择性通知),有异常需要再finally 进行释放

等待可中断:使用lock.lockInterruptibly() 实现,等待的线程可以放弃等待,改为处理其他事情

实现公平锁:公平就是先等待的线程先获得锁,默认是不公平的,通过ReentrantLock(boolean) 构造方法来设置公平不公平

可选择性通知:线程对象可以注册再Condition 中,从而可以选择性的进行线程通知,使用notify 和 notifyall 来通知,用ReentrantLock 类结合Condition 实例可以实现"选择性通知"

满足需求的情况先,优先使用synchronized

## 2.1. volatile关键字

修饰变量,这个变量是稳定不变的,每次使用它都需要去共享内存中读取,作用是保证变量的可见性,防止指令重排

### 2.2 并发的三个重要特性

原子性:一次操作,要么都执行,要么都不执行,synchronized保证

可见性:当一个线程对共享变量进行修改,另外的线程立刻可以啊看到修改后的值,volatile保证

有序性:执行时有先后,java编译器会进行优化,执行顺序未必就是编写顺序,volatile 可以禁止指令重排

### 2.3说说 synchronized 关键字和 volatile 关键字的区别

synchronized:修饰方法,代码块 ,性能差点,会阻塞,原子性和可见性都能保证,多线程访问资源的同步性

volatile:修饰变量,性能好,不会阻塞,可见性和有序性可以保证,解决变量在多线程之间的可见性

## 3.1. ThreadLocal简介

![image-20200816211618398](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200816211618398.png)

是一个类,主要的作用就是为每个线程都有一个本地专属的值,如果创建了一个ThreadLocal 变量,那么每个访问这个变量的线程都会有这个变量的本地副本,从而避免线程安全问题(两个人拿一个袋子收集宝物,肯定会产生争执,每人分配一个袋子就没问题)

## 3.3. ThreadLocal原理

set方法

```
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
    	map.set(this, value);
    else
    	createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
	return t.threadLocals;
}
```

![image-20200816212922313](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200816212922313.png)

最终变量是存在线程对象的ThreadLocalMap 上的,不是ThreadLocal上的,每个`Thread`对象中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为key ，Object 对象为 value的键值对。

## 3.4. ThreadLocal 内存泄露问题

ThreadLocalMap中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法

## 4.1. 为什么要用线程池？

就像cpu 的核心数一样,提供了一种限制和资源管理,线程池的好处,降低资源消耗(创建和销毁线程的损耗),提高响应速度(任务来时,不需要等待线程的创建就能立刻执行),提高线程的可管理性(统一分配 监控)

## 4.2. Runnable接口和Callable接口的区别

Runnable:接口 ,实现run()方法,任务执行完没有返回值或者抛出异常

Callable:接口,实现call()方法,有返回值和抛出异常

工具类Executors 可以实现Runnable 和 Callable 对象之间的互相转换

## 4.3. Executors执行execute()方法和submit()方法的区别？

execute():不需要返回值,无法判定任务执行成功与否

submit():返回Futrue,可以通过future 判断任务执行成功与否

## 4.4. 如何创建线程池

通过ThreadPoolExecutor 构造方法实现

通过工具类Executors 来实现(底层还是通过ThreadPoolExecutor 实现)

- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

### 4.4.1 ThreadPoolExecutor 参数

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
- **`unit`** : `keepAliveTime` 参数的时间单位。
- **`threadFactory`** :executor 创建新线程的时候会用到。
- **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

### 4.4.2 饱和策略

- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。
- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用自己的线程运行任务，如果应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。
- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。

### 4.4.3 线程池原理分析

线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行。

![image-20200816221038682](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200816221038682.png)



## 5.1. 介绍一下Atomic 原子类

就是具有原子/原子操作的类，再java.util.concurrent.atomic 下

## 5.2. JUC 包中的原子类是哪4类?

基本类型：

AtomicInteger

AtomicLong

AtomicBoolean 

数组类型：

AtomicIntegerArray

AtomicLongArray

AtomicReferenceArray

引用类型：

AtomicReference

AtomicStampedReference

AtomicMarkableReference

属性修改类型：

AtomicIntegerFieldUpdater

AtomicLongFieldUpdater

## 5.3. AtomicInteger 的使用

get()

getAndSet()

getAndIncrement()

getAndDecrement()

getAndAdd(int)

compareAndSet(int ,int)

lazySet(int)

## 5.4. AtomicInteger 类的原理

Atomic 主要使用CAS（期望的值和原本的值做比较）+volatile（value）+native （objectFieldOffset()）方法保证原子操作，避免关键字synchronized 的高开销，

## 6.1. AQS 介绍

全称AbstractQueuedSynchronizer，是一个用来构建锁和同步器的框架，比如ReentrantLock，Semaphore

## 6.2. AQS 原理分析

核心思想，如果被请求的资的共享资源空闲，则将当前线程设置为有效的工作线程，并将资源设置为锁定状态，若被占用，使用阻塞等待以及被唤醒时锁分配的机制，AQS 使用的是CLH队列锁实现的，将暂时获取不到锁的线程加入队列中。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。

## 6.2.2. AQS 对资源的共享方式

独占：只有一个线程可以执行，如ReentrantLock（公平和不公平）

共享：多个线程可以同时执行，如Semaphore/CountDownLatch

ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。

### 6.2.3. AQS底层使用了模板方法模式

使用者继承AbstractQueuedSynchronizer 并重写指定的方法（对共享资源state的获取和释放），需要重写一下方法

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

## 6.3. AQS 组件总结

- **Semaphore(信号量)-允许多个线程同时访问：** synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。
- **CountDownLatch （倒计时器）：** 这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。
- **CyclicBarrier(循环栅栏)：** 它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。

# 一 JDK 提供的并发容器总结

JDK 提供的这些容器大部分在 `java.util.concurrent` 包中。

- **ConcurrentHashMap（类）:** 线程安全的 HashMap
- **CopyOnWriteArrayList（类）:** 线程安全的 List，在读多写少（读共享写互斥）的场合性能非常好，远远好于 Vector.
- **ConcurrentLinkedQueue（类）:** 高效的并发队列（非阻塞队列），使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
- **BlockingQueue（接口）:** 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
- **ConcurrentSkipListMap:** 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。



## 3.2 CopyOnWriteArrayList 是如何做到的？

`CopyOnWriteArrayList` 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

在计算机中，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。

## 3.3 CopyOnWriteArrayList 读取和写入源码简单分析

读取

```java
/** The array, accessed only via getArray/setArray. */
    private transient volatile Object[] array;
    public E get(int index) {
        return get(getArray(), index);
    }
    @SuppressWarnings("unchecked")
    private E get(Object[] a, int index) {
        return (E) a[index];
    }
    final Object[] getArray() {
        return array;
    }
```

写入

```java
 /**
     * Appends the specified element to the end of this list.
     *
     * @param e element to be appended to this list
     * @return {@code true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();//加锁
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();//释放锁
        }
    }
```



# 四 ConcurrentLinkedQueue

Java 提供的线程安全的 Queue 可以分为**阻塞队列**和**非阻塞队列**，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue。 **阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。**ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法来实现线程安全。

# 五 BlockingQueue

接口，实现类有以下方法

**ArrayBlockingQueue**：是 BlockingQueue 接口的有界队列实现类，底层采用**数组**来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。

**LinkedBlockingQueue**： 底层基于**单向链表**实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。

**PriorityBlockingQueue**：是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 `compareTo()` 方法来指定元素排序规则，或者初始化时通过构造器参数 `Comparator` 来指定排序规则。 并发控制采用的是**ReentrantLock**，队列为无界队列（ArrayBlockingQueue 是有界队列，LinkedBlockingQueue 也可以通过在构造函数中传入 capacity 指定队列最大的容量，但是 PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，**如果空间不够的话会自动扩容**）。

# 一 使用线程池的好处

**线程池**提供了一种限制和管理资源（包括执行一个任务）。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

# 二 Executor 框架

通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外,还有关键的一点：有助于避免 this 逃逸问题。

## 2.2 Executor 框架结构(主要由三大部分组成)

**任务(Runnable /Callable)**,任务的实现都可以被executor执行
**任务的执行(Executor)**，Executor是接口，ExecutorService 也是接口，实现类有ThreadPoolExecutor，ScheduledThreadPoolExecutor

![image-20200823100115749](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200823100115749.png)

**异步计算的结果(Future),**future（接口） 和 futuretask （接口）都可以代表一部计算的结果，我们把任务交给executor执行，submit调用后回返回一个futuretask对象。

## 3.1 ThreadPoolExecutor 参数

- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。
- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
- **`unit`** : `keepAliveTime` 参数的时间单位。
- **`threadFactory`** :executor 创建新线程的时候会用到。
- **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。

## 3.2 推荐使用 ThreadPoolExecutor 构造函数创建线程池

推荐使用ThreadPoolExecutor 来创建线程，而不是使用Executors 来创建线程。

## 4.2 线程池原理分析

![image-20200823101614344](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200823101614344.png)

4.3 几个常见的对比
Runnable vs Callable：Runnable不会返回结果和异常，callable 可以
execute() vs submit()：execute 用于不需要返回值的任务，submit 返回 future 对象。
shutdown() vs shutdownNow()：都是关闭线程池，shutdown状态为shutdown，不再接受新任务，队列里的任务要执行完毕，shutdonwnow 的状态时stop ，中止任务，返回任务队列list


# 五 几种常见的线程池详解

FixedThreadPool：被称为可重用固定线程数的线程池，任务较多，无界队列会oom

SingleThreadExecutor：只有一个线程的线程池，无界队列会oom

CachedThreadPool 详解：会根据需要创建新线程的线程池，`maximumPoolSize`被设置为 Integer.MAX.VALUE，即它是无界的，不断创建新的线程产生oom


# 六 ScheduledThreadPoolExecutor 详解

`ScheduledThreadPoolExecutor` 主要用来在给定的延迟后运行任务，或者定期执行任务。

# 七 线程池大小确定

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。

- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

  **如何判断是cpu密集型还是i/o密集型**：CPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。单凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。

# 何谓悲观锁与乐观锁

**悲观锁**：总假设最好的情况，认为没人跟你竞争，适合多读
**乐观锁**：总假设最坏的情况，认为就是在竞争，资源每次只给一个线程使用，适合多写

# 乐观锁常见的两种实现方式

1. **版本号机制**，表中设置字段，将预期值和真实值比较
2. **CAS算法**，比较和交换，无锁算法，设置三个操作数，需要读写的 内存值v,进行比较的值a，拟写入的新值b，当且仅当v==a时，CAS通过原子方式用新值b来更新v的值。失败进行自旋操作，就是不断重试。
3. **乐观锁的缺点**
    ABA 问题：其他线程修改为B，然后又修改为A
    CAS不成功循环时间长开销大
    只能保证一个共享变量的原子操作
    CAS与synchronized的使用情景

## 2.1 程序计数器

字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。

**注意：程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。**

## 2.2 Java 虚拟机栈

与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。

Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。

**局部变量表主要存放了编译期可知的各种数据类型**（boolean、byte、char、short、int、float、long、double）、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）

**Java 虚拟机栈会出现两种错误：`StackOverFlowError` 和 `OutOfMemoryError`。**

## 2.4 堆

堆内存被通常被分为下面三部分：

1. 新生代内存(Young Generation)
2. 老生代(Old Generation)
3. 永生代(Permanent Generation)

## 2.5 方法区

它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 **Java 虚拟机规范把方法区描述为堆的一个逻辑部分**，但是它却有一个别名叫做 **Non-Heap（非堆）**

## 2.5.1 方法区和永久代的关系

**方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。**


## 3.1 对象的创建

Step1:类加载检查
Step2:分配内存
Step3:初始化零值
Step4:设置对象头
Step5:执行 init 方法

## 4.2 String s1 = new String("abc");这句话创建了几个字符串对象？

**将创建 1 或 2 个字符串。如果池中已存在字符串常量“abc”，则只会在堆空间创建一个字符串常量“abc”。如果池中没有字符串常量“abc”，那么它将首先在池中创建，然后在堆空间中创建，因此将创建总共 2 个字符串对象。**

## 4.3 8 种基本类型的包装类和常量池

**Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean；前面 4 种包装类默认创建了数值[-128，127] 的相应类型的缓存数据，Character创建了数值在[0,127]范围的缓存数据，Boolean 直接返回True Or False。如果超出对应范围仍然会去创建新的对象。**

## 1.2 大对象直接进入老年代

避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。

## 1.3 主要gc的区域

- 部分收集 (Partial GC)：

  - 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
  - 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
  - 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

  整堆收集 (Full GC)：收集整个 Java 堆和方法区。

# 2 对象已经死亡？

## 2.1 引用计数法

**这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。**

## 2.2 可达性分析算法

**“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

## 2.4 不可达的对象并非“非死不可”

1. 如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。
2. GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了

## 2.6 如何判断一个类是无用的类

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
- 加载该类的 ClassLoader 已经被回收。
- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

# 3 垃圾收集算法

## 3.1 标记-清除算法

## 3.2 复制算法

## 3.3 标记-整理算法

## 3.4 分代收集算法

**比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**

# 4 垃圾收集器

![image-20200825094235247](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825094235247.png)

4.1 Serial 收集器：单线程收集器了
4.2 ParNew 收集器：ParNew 收集器其实就是 Serial 收集器的多线程版本
4.3 Parallel Scavenge 收集器：Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。
4.4.Serial Old 收集器：Serial 收集器的老年代版本
4.5 Parallel Old 收集器：Parallel Scavenge 收集器的老年代版本
4.6 CMS 收集器：CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。

- **初始标记：** 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
- **并发标记：** 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- **重新标记：** 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- **并发清除：** 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。

缺点：

- **对 CPU 资源敏感；**
- **无法处理浮动垃圾；**
- **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**

## 4.7 G1 收集器

**G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.**

- **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
- **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
- **空间整合**：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。
- **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

# 类的生命周期

![image-20200824215038631](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200824215038631.png)

类加载过程：加载、链接、初始化
加载：一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 `loadClass()` 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。
验证：文件格式、字节码、符号引用验证
准备：准备阶段是正式为类变量分配内存并设置类变量初始值的阶段
解析
初始化
卸载

# 类加载器总结

1. **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由C++实现，负责加载 `%JAVA_HOME%/lib`目录下的jar包和类或者或被 `-Xbootclasspath`参数指定的路径中的所有类。
2. **ExtensionClassLoader(扩展类加载器)** ：主要负责加载目录 `%JRE_HOME%/lib/ext` 目录下的jar包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的jar包。
3. **AppClassLoader(应用程序类加载器)** :面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。

# 双亲委派模型

![image-20200824215727757](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200824215727757.png)

# 双亲委派模型的好处

双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。

# 如果我们不想要双亲委派模型怎么办？

**自定义加载器的话，需要继承 `ClassLoader` 。如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 `loadClass()` 方法**

# Java内存区域常见配置参数概览

## 堆参数

![image-20200825093914024](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825093914024.png)

## 回收器参数；

![image-20200825093939745](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825093939745.png)

## 常用组合；

![](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825094531578.png)

## GC 调优策略

**策略 1：**将新对象预留在新生代，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。

**策略 2：**大对象进入老年代,可能会出现频繁的 full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说简直就是噩梦）。`-XX:PretenureSizeThreshold` 可以设置直接进入老年代的对象大小。

**策略 3：**合理设置进入老年代对象的年龄，`-XX:MaxTenuringThreshold` 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率。

**策略 4：**设置稳定的堆大小，堆大小设置有两个参数：`-Xms` 初始化堆大小，`-Xmx` 最大堆大小。

**策略5：**注意： 如果满足下面的指标，**则一般不需要进行 GC 优化：**

> MinorGC 执行时间不到50ms； Minor GC 执行不频繁，约10秒一次； Full GC 执行时间不到1s； Full GC 执行频率不算频繁，不低于10分钟1次。

## 堆分配空间策略

官方推荐新生代占java堆的3/8，幸存代占新生代的1/10

## 2.2 NIO的特性/NIO与IO区别

**IO流是阻塞的，NIO流是不阻塞的。**

**IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。**

**NIO 通过Channel（通道） 进行读写。**

**NIO有选择器，而IO没有。**

## MyISAM和InnoDB区别

MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁还有外键，而且最大的缺陷就是崩溃后无法安全恢复。

## 索引

MySQL索引使用的数据结构主要有**BTree索引** 和 **哈希索引** 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为**单条记录**查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

MySQL的BTree索引使用的是B树中的**B+Tree**，但对于主要的两种存储引擎的实现方式是不同的。

- **MyISAM:** B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。
- **InnoDB:** 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。**在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。** **因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。** 

## 不可重读和幻读的区别?

**不可重复读和幻读区别：**不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

## 大表优化

#### 1. 限定数据的范围

务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；

#### 2. 读/写分离

经典的数据库拆分方案，主库负责写，从库负责读；

#### 3. 垂直分区

**根据数据库里面数据表的相关性进行拆分。** 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。

- **垂直拆分的优点：** 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。
- **垂直拆分的缺点：** 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂；

#### 4.水平分区

**保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 **水平拆分最好分库** 。

水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨节点Join性能较差，逻辑复杂。**尽量不要对数据进行分片**，**因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

**数据库分片的两种常见方案：**

- **客户端代理：** **分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
- **中间件代理：** **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。

## 分库分表之后,id 主键如何处理？

- **UUID**：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。
- **数据库自增 id** : 两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的 id 有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。
- **利用 redis 生成 id :** 性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。
- **Twitter的snowflake算法** ：Github 地址：https://github.com/twitter-archive/snowflake。

![image-20200825131214949](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825131214949.png)

- **美团的[Leaf](https://tech.meituan.com/2017/04/21/mt-leaf.html)分布式ID生成系统** ：Leaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。感觉还不错。美团技术团队的一篇文章：https://tech.meituan.com/2017/04/21/mt-leaf.html 。

### 基本操作

```
/* Windows服务 */
-- 启动MySQL
    net start mysql
-- 创建Windows服务
    sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)
/* 连接与断开服务器 */
mysql -h 地址 -P 端口 -u 用户名 -p 密码
SHOW PROCESSLIST -- 显示哪些线程正在运行
SHOW VARIABLES -- 显示系统变量信息
```

### 数据库操作

```
/* 数据库操作 */ ------------------
-- 查看当前数据库
    SELECT DATABASE();
-- 显示当前时间、用户名、数据库版本
    SELECT now(), user(), version();
-- 创建库
    CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项
    数据库选项：
        CHARACTER SET charset_name
        COLLATE collation_name
-- 查看已有库
    SHOW DATABASES[ LIKE 'PATTERN']
-- 查看当前库信息
    SHOW CREATE DATABASE 数据库名
-- 修改库的选项信息
    ALTER DATABASE 库名 选项信息
-- 删除库
    DROP DATABASE[ IF EXISTS] 数据库名
        同时删除该数据库相关的目录及其目录内容
```

### 表的操作

```
-- 创建表
    CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项]
        每个字段必须有数据类型
        最后一个字段后不能有逗号
        TEMPORARY 临时表，会话结束时表自动消失
        对于字段的定义：
            字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string']
-- 表选项
    -- 字符集
        CHARSET = charset_name
        如果表没有设定，则使用数据库字符集
    -- 存储引擎
        ENGINE = engine_name
        表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同
        常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive
        不同的引擎在保存表的结构和数据时采用不同的方式
        MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引
        InnoDB表文件含义：.frm表定义，表空间数据和日志文件
        SHOW ENGINES -- 显示存储引擎的状态信息
        SHOW ENGINE 引擎名 {LOGS|STATUS} -- 显示存储引擎的日志或状态信息
    -- 自增起始数
    	AUTO_INCREMENT = 行数
    -- 数据文件目录
        DATA DIRECTORY = '目录'
    -- 索引文件目录
        INDEX DIRECTORY = '目录'
    -- 表注释
        COMMENT = 'string'
    -- 分区选项
        PARTITION BY ... (详细见手册)
-- 查看所有表
    SHOW TABLES[ LIKE 'pattern']
    SHOW TABLES FROM  库名
-- 查看表结构
    SHOW CREATE TABLE 表名 （信息更详细）
    DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE 'PATTERN']
    SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']
-- 修改表
    -- 修改表本身的选项
        ALTER TABLE 表名 表的选项
        eg: ALTER TABLE 表名 ENGINE=MYISAM;
    -- 对表进行重命名
        RENAME TABLE 原表名 TO 新表名
        RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库）
        -- RENAME可以交换两个表名
    -- 修改表的字段机构（13.1.2. ALTER TABLE语法）
        ALTER TABLE 表名 操作名
        -- 操作名
            ADD[ COLUMN] 字段定义       -- 增加字段
                AFTER 字段名          -- 表示增加在该字段名后面
                FIRST               -- 表示增加在第一个
            ADD PRIMARY KEY(字段名)   -- 创建主键
            ADD UNIQUE [索引名] (字段名)-- 创建唯一索引
            ADD INDEX [索引名] (字段名) -- 创建普通索引
            DROP[ COLUMN] 字段名      -- 删除字段
            MODIFY[ COLUMN] 字段名 字段属性     -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上)
            CHANGE[ COLUMN] 原字段名 新字段名 字段属性      -- 支持对字段名修改
            DROP PRIMARY KEY    -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性)
            DROP INDEX 索引名 -- 删除索引
            DROP FOREIGN KEY 外键    -- 删除外键
-- 删除表
    DROP TABLE[ IF EXISTS] 表名 ...
-- 清空表数据
    TRUNCATE [TABLE] 表名
-- 复制表结构
    CREATE TABLE 表名 LIKE 要复制的表名
-- 复制表结构和数据
    CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名
-- 检查表是否有错误
    CHECK TABLE tbl_name [, tbl_name] ... [option] ...
-- 优化表
    OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...
-- 修复表
    REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]
-- 分析表
    ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...
```

### 数据操作

```
/* 数据操作 */ ------------------
-- 增
    INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...]
        -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。
        -- 可同时插入多条数据记录！
        REPLACE 与 INSERT 完全一样，可互换。
    INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...]
-- 查
    SELECT 字段列表 FROM 表名[ 其他子句]
        -- 可来自多个表的多个字段
        -- 其他子句可以不使用
        -- 字段列表可以用*代替，表示所有字段
-- 删
    DELETE FROM 表名[ 删除条件子句]
        没有条件子句，则会删除全部
-- 改
    UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件]
```

### 字符集编码

```
/* 字符集编码 */ ------------------
-- MySQL、数据库、表、字段均可设置编码
-- 数据编码与客户端编码不需一致
SHOW VARIABLES LIKE 'character_set_%'   -- 查看所有字符集编码项
    character_set_client        客户端向服务器发送数据时使用的编码
    character_set_results       服务器端将结果返回给客户端所使用的编码
    character_set_connection    连接层编码
SET 变量名 = 变量值
    SET character_set_client = gbk;
    SET character_set_results = gbk;
    SET character_set_connection = gbk;
SET NAMES GBK;  -- 相当于完成以上三个设置
-- 校对集
    校对集用以排序
    SHOW CHARACTER SET [LIKE 'pattern']/SHOW CHARSET [LIKE 'pattern']   查看所有字符集
    SHOW COLLATION [LIKE 'pattern']     查看所有校对集
    CHARSET 字符集编码     设置字符集编码
    COLLATE 校对集编码     设置校对集编码
```

### 数据类型(列类型)

```
/* 数据类型（列类型） */ ------------------
1. 数值类型
-- a. 整型 ----------
    类型         字节     范围（有符号位）
    tinyint     1字节    -128 ~ 127      无符号位：0 ~ 255
    smallint    2字节    -32768 ~ 32767
    mediumint   3字节    -8388608 ~ 8388607
    int         4字节
    bigint      8字节
    int(M)  M表示总位数
    - 默认存在符号位，unsigned 属性修改
    - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改
        例：int(5)   插入一个数'123'，补填后为'00123'
    - 在满足要求的情况下，越小越好。
    - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。
-- b. 浮点型 ----------
    类型             字节     范围
    float(单精度)     4字节
    double(双精度)    8字节
    浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。
        不同于整型，前后均会补填0.
    定义浮点型时，需指定总位数和小数位数。
        float(M, D)     double(M, D)
        M表示总位数，D表示小数位数。
        M和D的大小会决定浮点数的范围。不同于整型的固定范围。
        M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。
        支持科学计数法表示。
        浮点数表示近似值。
-- c. 定点数 ----------
    decimal -- 可变长度
    decimal(M, D)   M也表示总位数，D表示小数位数。
    保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。
    将浮点数转换为字符串来保存，每9位数字保存为4个字节。
2. 字符串类型
-- a. char, varchar ----------
    char    定长字符串，速度快，但浪费空间
    varchar 变长字符串，速度慢，但节省空间
    M表示能存储的最大长度，此长度是字符数，非字节数。
    不同的编码，所占用的空间不同。
    char,最多255个字符，与编码无关。
    varchar,最多65535字符，与编码有关。
    一条有效记录最大不能超过65535个字节。
        utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符
    varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。
    varchar 的最大有效长度由最大行大小和使用的字符集确定。
    最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是65535-1-2=65532字节。
    例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3
-- b. blob, text ----------
    blob 二进制字符串（字节字符串）
        tinyblob, blob, mediumblob, longblob
    text 非二进制字符串（字符字符串）
        tinytext, text, mediumtext, longtext
    text 在定义时，不需要定义长度，也不会计算总长度。
    text 类型在定义时，不可给default值
-- c. binary, varbinary ----------
    类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。
    char, varchar, text 对应 binary, varbinary, blob.
3. 日期时间类型
    一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。
    datetime    8字节    日期及时间     1000-01-01 00:00:00 到 9999-12-31 23:59:59
    date        3字节    日期         1000-01-01 到 9999-12-31
    timestamp   4字节    时间戳        19700101000000 到 2038-01-19 03:14:07
    time        3字节    时间         -838:59:59 到 838:59:59
    year        1字节    年份         1901 - 2155
datetime    YYYY-MM-DD hh:mm:ss
timestamp   YY-MM-DD hh:mm:ss
            YYYYMMDDhhmmss
            YYMMDDhhmmss
            YYYYMMDDhhmmss
            YYMMDDhhmmss
date        YYYY-MM-DD
            YY-MM-DD
            YYYYMMDD
            YYMMDD
            YYYYMMDD
            YYMMDD
time        hh:mm:ss
            hhmmss
            hhmmss
year        YYYY
            YY
            YYYY
            YY
4. 枚举和集合
-- 枚举(enum) ----------
enum(val1, val2, val3...)
    在已知的值中进行单选。最大数量为65535.
    枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。
    表现为字符串类型，存储却是整型。
    NULL值的索引是NULL。
    空字符串错误值的索引值是0。
-- 集合（set） ----------
set(val1, val2, val3...)
    create table tab ( gender set('男', '女', '无') );
    insert into tab values ('男, 女');
    最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。
    当创建表时，SET成员值的尾部空格将自动被删除。
```

### 列属性(列约束)

```
/* 列属性（列约束） */ ------------------
1. PRIMARY 主键
    - 能唯一标识记录的字段，可以作为主键。
    - 一个表只能有一个主键。
    - 主键具有唯一性。
    - 声明字段时，用 primary key 标识。
        也可以在字段列表之后声明
            例：create table tab ( id int, stu varchar(10), primary key (id));
    - 主键字段的值不能为null。
    - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。
        例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));
2. UNIQUE 唯一索引（唯一约束）
    使得某字段的值也不能重复。
3. NULL 约束
    null不是数据类型，是列的一个属性。
    表示当前列是否可以为null，表示什么都没有。
    null, 允许为空。默认。
    not null, 不允许为空。
    insert into tab values (null, 'val');
        -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null
4. DEFAULT 默认值属性
    当前字段的默认值。
    insert into tab values (default, 'val');    -- 此时表示强制使用默认值。
    create table tab ( add_time timestamp default current_timestamp );
        -- 表示将当前时间的时间戳设为默认值。
        current_date, current_time
5. AUTO_INCREMENT 自动增长约束
    自动增长必须为索引（主键或unique）
    只能存在一个字段为自动增长。
    默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;
6. COMMENT 注释
    例：create table tab ( id int ) comment '注释内容';
7. FOREIGN KEY 外键约束
    用于限制主表与从表数据完整性。
    alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id);
        -- 将表t1的t1_id外键关联到表t2的id字段。
        -- 每个外键都有一个名字，可以通过 constraint 指定
    存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。
    作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。
    MySQL中，可以对InnoDB引擎使用外键约束：
    语法：
    foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作]
    此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。
    可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。
    如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择：
    1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。
    2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。
    3. restrict，拒绝父表删除和更新。
    注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。
```

### 建表规范

```
/* 建表规范 */ ------------------
    -- Normal Format, NF
        - 每个表保存一个实体信息
        - 每个具有一个ID字段作为主键
        - ID主键 + 原子表
    -- 1NF, 第一范式
        字段不能再分，就满足第一范式。
    -- 2NF, 第二范式
        满足第一范式的前提下，不能出现部分依赖。
        消除复合主键就可以避免部分依赖。增加单列关键字。
    -- 3NF, 第三范式
        满足第二范式的前提下，不能出现传递依赖。
        某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。
        将一个实体信息的数据放在一个表内实现。
```

### SELECT

```
/* SELECT */ ------------------
SELECT [ALL|DISTINCT] select_expr FROM -> WHERE -> GROUP BY [合计函数] -> HAVING -> ORDER BY -> LIMIT
a. select_expr
    -- 可以用 * 表示所有字段。
        select * from tb;
    -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）
        select stu, 29+25, now() from tb;
    -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。
        - 使用 as 关键字，也可省略 as.
        select stu+10 as add10 from tb;
b. FROM 子句
    用于标识查询来源。
    -- 可以为表起别名。使用as关键字。
        SELECT * FROM tb1 AS tt, tb2 AS bb;
    -- from子句后，可以同时出现多个表。
        -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。
        SELECT * FROM tb1, tb2;
    -- 向优化符提示如何选择索引
        USE INDEX、IGNORE INDEX、FORCE INDEX
        SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;
        SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;
c. WHERE 子句
    -- 从from获得的数据源中进行筛选。
    -- 整型1表示真，0表示假。
    -- 表达式由运算符和运算数组成。
        -- 运算数：变量（字段）、值、函数返回值
        -- 运算符：
            =, <=>, <>, !=, <=, <, >=, >, !, &&, ||,
            in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor
            is/is not 加上ture/false/unknown，检验某个值的真假
            <=>与<>功能相同，<=>可用于null比较
d. GROUP BY 子句, 分组子句
    GROUP BY 字段/别名 [排序方式]
    分组后会进行排序。升序：ASC，降序：DESC
    以下[合计函数]需配合 GROUP BY 使用：
    count 返回不同的非NULL值数目  count(*)、count(字段)
    sum 求和
    max 求最大值
    min 求最小值
    avg 求平均值
    group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。
e. HAVING 子句，条件子句
    与 where 功能、用法相同，执行时机不同。
    where 在开始时执行检测数据，对原数据进行过滤。
    having 对筛选出的结果再次进行过滤。
    having 字段必须是查询出来的，where 字段必须是数据表存在的。
    where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。
    where 不可以使用合计函数。一般需用合计函数才会用 having
    SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。
f. ORDER BY 子句，排序子句
    order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...
    升序：ASC，降序：DESC
    支持多个字段的排序。
g. LIMIT 子句，限制结果数量子句
    仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。
    limit 起始位置, 获取条数
    省略第一个参数，表示从索引0开始。limit 获取条数
h. DISTINCT, ALL 选项
    distinct 去除重复记录
    默认为 all, 全部记录
```

### UNION

```
/* UNION */ ------------------
    将多个select查询的结果组合成一个结果集合。
    SELECT ... UNION [ALL|DISTINCT] SELECT ...
    默认 DISTINCT 方式，即所有返回的行都是唯一的
    建议，对每个SELECT查询加上小括号包裹。
    ORDER BY 排序时，需加上 LIMIT 进行结合。
    需要各select查询的字段数量一样。
    每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。
```

### 子查询

```
/* 子查询 */ ------------------
    - 子查询需用括号包裹。
-- from型
    from后要求是一个表，必须给子查询结果取个别名。
    - 简化每个查询内的条件。
    - from型需将结果生成一个临时表格，可用以原表的锁定的释放。
    - 子查询返回一个表，表型子查询。
    select * from (select * from tb where id>0) as subfrom where id>1;
-- where型
    - 子查询返回一个值，标量子查询。
    - 不需要给子查询取别名。
    - where子查询内的表，不能直接用以更新。
    select * from tb where money = (select max(money) from tb);
    -- 列子查询
        如果子查询结果返回的是一列。
        使用 in 或 not in 完成查询
        exists 和 not exists 条件
            如果子查询返回数据，则返回1或0。常用于判断条件。
            select column1 from t1 where exists (select * from t2);
    -- 行子查询
        查询条件是一个行。
        select * from t1 where (id, gender) in (select id, gender from t2);
        行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...)
        行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。
    -- 特殊运算符
    != all()    相当于 not in
    = some()    相当于 in。any 是 some 的别名
    != some()   不等同于 not in，不等于其中某一个。
    all, some 可以配合其他运算符一起使用。
```

### 连接查询(join)

```
/* 连接查询(join) */ ------------------
    将多个表的字段进行连接，可以指定连接条件。
-- 内连接(inner join)
    - 默认就是内连接，可省略inner。
    - 只有数据存在时才能发送连接。即连接结果不能出现空行。
    on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真）
    也可用where表示连接条件。
    还有 using, 但需字段名相同。 using(字段名)
    -- 交叉连接 cross join
        即，没有条件的内连接。
        select * from tb1 cross join tb2;
-- 外连接(outer join)
    - 如果数据不存在，也会出现在连接结果中。
    -- 左外连接 left join
        如果数据不存在，左表记录会出现，而右表为null填充
    -- 右外连接 right join
        如果数据不存在，右表记录会出现，而左表为null填充
-- 自然连接(natural join)
    自动判断连接条件完成连接。
    相当于省略了using，会自动查找相同字段名。
    natural join
    natural left join
    natural right join
select info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;
```

### TRUNCATE

```
/* TRUNCATE */ ------------------
TRUNCATE [TABLE] tbl_name
清空数据
删除重建表
区别：
1，truncate 是删除表再创建，delete 是逐条删除
2，truncate 重置auto_increment的值。而delete不会
3，truncate 不知道删除了几条，而delete知道。
4，当被用于带分区的表时，truncate 会保留分区
```

### 备份与还原

```
/* 备份与还原 */ ------------------
备份，将数据的结构与表内数据保存起来。
利用 mysqldump 指令完成。
-- 导出
mysqldump [options] db_name [tables]
mysqldump [options] ---database DB1 [DB2 DB3...]
mysqldump [options] --all--database
1. 导出一张表
　　mysqldump -u用户名 -p密码 库名 表名 > 文件名(D:/a.sql)
2. 导出多张表
　　mysqldump -u用户名 -p密码 库名 表1 表2 表3 > 文件名(D:/a.sql)
3. 导出所有表
　　mysqldump -u用户名 -p密码 库名 > 文件名(D:/a.sql)
4. 导出一个库
　　mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 > 文件名(D:/a.sql)
可以-w携带WHERE条件
-- 导入
1. 在登录mysql的情况下：
　　source  备份文件
2. 在不登录的情况下
　　mysql -u用户名 -p密码 库名 < 备份文件
```

### 视图

```
什么是视图：
    视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。
    视图具有表结构文件，但不存在数据文件。
    对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。
    视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。
-- 创建视图
CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement
    - 视图名必须唯一，同时不能与表重名。
    - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。
    - 可以指定视图执行的算法，通过ALGORITHM指定。
    - column_list如果存在，则数目必须等于SELECT语句检索的列数
-- 查看结构
    SHOW CREATE VIEW view_name
-- 删除视图
    - 删除视图后，数据依然存在。
    - 可同时删除多个视图。
    DROP VIEW [IF EXISTS] view_name ...
-- 修改视图结构
    - 一般不修改视图，因为不是所有的更新视图都会映射到表上。
    ALTER VIEW view_name [(column_list)] AS select_statement
-- 视图作用
    1. 简化业务逻辑
    2. 对客户端隐藏真实的表结构
-- 视图算法(ALGORITHM)
    MERGE       合并
        将视图的查询语句，与外部查询需要先合并再执行！
    TEMPTABLE   临时表
        将视图执行完毕后，形成临时表，再做外层查询！
    UNDEFINED   未定义(默认)，指的是MySQL自主去选择相应的算法。
```

### 事务(transaction)

```
事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。
    - 支持连续SQL的集体成功或集体撤销。
    - 事务是数据库在数据完整性方面的一个功能。
    - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。
    - InnoDB被称为事务安全型引擎。
-- 事务开启
    START TRANSACTION; 或者 BEGIN;
    开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。
-- 事务提交
    COMMIT;
-- 事务回滚
    ROLLBACK;
    如果部分操作发生问题，映射到事务开启前。
-- 事务的特性
    1. 原子性（Atomicity）
        事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
    2. 一致性（Consistency）
        事务前后数据的完整性必须保持一致。
        - 事务开始和结束时，外部数据一致
        - 在整个事务过程中，操作是连续的
    3. 隔离性（Isolation）
        多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。
    4. 持久性（Durability）
        一个事务一旦被提交，它对数据库中的数据改变就是永久性的。
-- 事务的实现
    1. 要求是事务支持的表类型
    2. 执行一组相关的操作前开启事务
    3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。
-- 事务的原理
    利用InnoDB的自动提交(autocommit)特性完成。
    普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。
    而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。
-- 注意
    1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。
    2. 事务不能被嵌套
-- 保存点
    SAVEPOINT 保存点名称 -- 设置一个事务保存点
    ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点
    RELEASE SAVEPOINT 保存点名称 -- 删除保存点
-- InnoDB自动提交特性设置
    SET autocommit = 0|1;   0表示关闭自动提交，1表示开启自动提交。
    - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。
    - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是，
        SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接)
        而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务)
```

### 锁表

```
/* 锁表 */
表锁定只用于防止其它客户端进行不正当地读取和写入
MyISAM 支持表锁，InnoDB 支持行锁
-- 锁定
    LOCK TABLES tbl_name [AS alias]
-- 解锁
    UNLOCK TABLES
```

### 触发器

```
/* 触发器 */ ------------------
    触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象
    监听：记录的增加、修改、删除。
-- 创建触发器
CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt
    参数：
    trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。
    trigger_event指明了激活触发程序的语句的类型
        INSERT：将新行插入表时激活触发程序
        UPDATE：更改某一行时激活触发程序
        DELETE：从表中删除某一行时激活触发程序
    tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。
    trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构
-- 删除
DROP TRIGGER [schema_name.]trigger_name
可以使用old和new代替旧的和新的数据
    更新操作，更新前是old，更新后是new.
    删除操作，只有old.
    增加操作，只有new.
-- 注意
    1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。
-- 字符连接函数
concat(str1,str2,...])
concat_ws(separator,str1,str2,...)
-- 分支语句
if 条件 then
    执行语句
elseif 条件 then
    执行语句
else
    执行语句
end if;
-- 修改最外层语句结束符
delimiter 自定义结束符号
    SQL语句
自定义结束符号
delimiter ;     -- 修改回原来的分号
-- 语句块包裹
begin
    语句块
end
-- 特殊的执行
1. 只要添加记录，就会触发程序。
2. Insert into on duplicate key update 语法会触发：
    如果没有重复记录，会触发 before insert, after insert;
    如果有重复记录并更新，会触发 before insert, before update, after update;
    如果有重复记录但是没有发生更新，则触发 before insert, before update
3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert
```

### SQL编程

```
/* SQL编程 */ ------------------
--// 局部变量 ----------
-- 变量声明
    declare var_name[,...] type [default value]
    这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。
-- 赋值
    使用 set 和 select into 语句为变量赋值。
    - 注意：在函数内是可以使用全局变量（用户自定义的变量）
--// 全局变量 ----------
-- 定义、赋值
set 语句可以定义并为变量赋值。
set @var = value;
也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。
还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。
select @var:=20;
select @v1:=id, @v2=name from t1 limit 1;
select * from tbl_name where @var:=30;
select into 可以将表中查询获得的数据赋给变量。
    -| select max(height) into @max_height from tb;
-- 自定义变量名
为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。
@var=10;
    - 变量被定义后，在整个会话周期都有效（登录到退出）
--// 控制结构 ----------
-- if语句
if search_condition then
    statement_list   
[elseif search_condition then
    statement_list]
...
[else
    statement_list]
end if;
-- case语句
CASE value WHEN [compare-value] THEN result
[WHEN [compare-value] THEN result ...]
[ELSE result]
END
-- while循环
[begin_label:] while search_condition do
    statement_list
end while [end_label];
- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。
    -- 退出循环
        退出整个循环 leave
        退出当前循环 iterate
        通过退出的标签决定退出哪个循环
--// 内置函数 ----------
-- 数值函数
abs(x)          -- 绝对值 abs(-10.9) = 10
format(x, d)    -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46
ceil(x)         -- 向上取整 ceil(10.1) = 11
floor(x)        -- 向下取整 floor (10.1) = 10
round(x)        -- 四舍五入去整
mod(m, n)       -- m%n m mod n 求余 10%3=1
pi()            -- 获得圆周率
pow(m, n)       -- m^n
sqrt(x)         -- 算术平方根
rand()          -- 随机数
truncate(x, d)  -- 截取d位小数
-- 时间日期函数
now(), current_timestamp();     -- 当前日期时间
current_date();                 -- 当前日期
current_time();                 -- 当前时间
date('yyyy-mm-dd hh:ii:ss');    -- 获取日期部分
time('yyyy-mm-dd hh:ii:ss');    -- 获取时间部分
date_format('yyyy-mm-dd hh:ii:ss', '%d %y %a %d %m %b %j'); -- 格式化时间
unix_timestamp();               -- 获得unix时间戳
from_unixtime();                -- 从时间戳获得时间
-- 字符串函数
length(string)          -- string长度，字节
char_length(string)     -- string的字符个数
substring(str, position [,length])      -- 从str的position开始,取length个字符
replace(str ,search_str ,replace_str)   -- 在str中用replace_str替换search_str
instr(string ,substring)    -- 返回substring首次在string中出现的位置
concat(string [,...])   -- 连接字串
charset(str)            -- 返回字串字符集
lcase(string)           -- 转换成小写
left(string, length)    -- 从string2中的左边起取length个字符
load_file(file_name)    -- 从文件读取内容
locate(substring, string [,start_position]) -- 同instr,但可指定开始位置
lpad(string, length, pad)   -- 重复用pad加在string开头,直到字串长度为length
ltrim(string)           -- 去除前端空格
repeat(string, count)   -- 重复count次
rpad(string, length, pad)   --在str后用pad补充,直到长度为length
rtrim(string)           -- 去除后端空格
strcmp(string1 ,string2)    -- 逐字符比较两字串大小
-- 流程函数
case when [condition] then result [when [condition] then result ...] [else result] end   多分支
if(expr1,expr2,expr3)  双分支。
-- 聚合函数
count()
sum();
max();
min();
avg();
group_concat()
-- 其他常用函数
md5();
default();
--// 存储函数，自定义函数 ----------
-- 新建
    CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型
        函数体
    - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。
    - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。
    - 参数部分，由"参数名"和"参数类型"组成。多个参数用逗号隔开。
    - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。
    - 多条语句应该使用 begin...end 语句块包含。
    - 一定要有 return 返回值语句。
-- 删除
    DROP FUNCTION [IF EXISTS] function_name;
-- 查看
    SHOW FUNCTION STATUS LIKE 'partten'
    SHOW CREATE FUNCTION function_name;
-- 修改
    ALTER FUNCTION function_name 函数选项
--// 存储过程，自定义功能 ----------
-- 定义
存储存储过程 是一段代码（过程），存储在数据库中的sql组成。
一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。
而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。
-- 创建
CREATE PROCEDURE sp_name (参数列表)
    过程体
参数列表：不同于函数的参数列表，需要指明参数类型
IN，表示输入型
OUT，表示输出型
INOUT，表示混合型
注意，没有返回值。
```

### 存储过程

```
/* 存储过程 */ ------------------
存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。
调用：CALL 过程名
-- 注意
- 没有返回值。
- 只能单独调用，不可夹杂在其他语句中
-- 参数
IN|OUT|INOUT 参数名 数据类型
IN      输入：在调用过程中，将数据输入到过程体内部的参数
OUT     输出：在调用过程中，将过程体处理完的结果返回到客户端
INOUT   输入输出：既可输入，也可输出
-- 语法
CREATE PROCEDURE 过程名 (参数列表)
BEGIN
    过程体
END
```

### 用户和权限管理

```
/* 用户和权限管理 */ ------------------
-- root密码重置
1. 停止MySQL服务
2.  [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &
    [Windows] mysqld --skip-grant-tables
3. use mysql;
4. UPDATE `user` SET PASSWORD=PASSWORD("密码") WHERE `user` = "root";
5. FLUSH PRIVILEGES;
用户信息表：mysql.user
-- 刷新权限
FLUSH PRIVILEGES;
-- 增加用户
CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串)
    - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。
    - 只能创建用户，不能赋予权限。
    - 用户名，注意引号：如 'user_name'@'192.168.1.1'
    - 密码也需引号，纯数字密码也要加引号
    - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD
-- 重命名用户
RENAME USER old_user TO new_user
-- 设置密码
SET PASSWORD = PASSWORD('密码')  -- 为当前用户设置密码
SET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码
-- 删除用户
DROP USER 用户名
-- 分配权限/添加用户
GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] 'password']
    - all privileges 表示所有权限
    - *.* 表示所有库的所有表
    - 库名.表名 表示某库下面的某表
    GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817';
-- 查看权限
SHOW GRANTS FOR 用户名
    -- 查看当前用户权限
    SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();
-- 撤消权限
REVOKE 权限列表 ON 表名 FROM 用户名
REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名   -- 撤销所有权限
-- 权限层级
-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。
全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user
    GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。
数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host
    GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。
表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv
    GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。
列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv
    当使用REVOKE时，您必须指定与被授权列相同的列。
-- 权限列表
ALL [PRIVILEGES]    -- 设置除GRANT OPTION之外的所有简单权限
ALTER   -- 允许使用ALTER TABLE
ALTER ROUTINE   -- 更改或取消已存储的子程序
CREATE  -- 允许使用CREATE TABLE
CREATE ROUTINE  -- 创建已存储的子程序
CREATE TEMPORARY TABLES     -- 允许使用CREATE TEMPORARY TABLE
CREATE USER     -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。
CREATE VIEW     -- 允许使用CREATE VIEW
DELETE  -- 允许使用DELETE
DROP    -- 允许使用DROP TABLE
EXECUTE     -- 允许用户运行已存储的子程序
FILE    -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILE
INDEX   -- 允许使用CREATE INDEX和DROP INDEX
INSERT  -- 允许使用INSERT
LOCK TABLES     -- 允许对您拥有SELECT权限的表使用LOCK TABLES
PROCESS     -- 允许使用SHOW FULL PROCESSLIST
REFERENCES  -- 未被实施
RELOAD  -- 允许使用FLUSH
REPLICATION CLIENT  -- 允许用户询问从属服务器或主服务器的地址
REPLICATION SLAVE   -- 用于复制型从属服务器（从主服务器中读取二进制日志事件）
SELECT  -- 允许使用SELECT
SHOW DATABASES  -- 显示所有数据库
SHOW VIEW   -- 允许使用SHOW CREATE VIEW
SHUTDOWN    -- 允许使用mysqladmin shutdown
SUPER   -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。
UPDATE  -- 允许使用UPDATE
USAGE   -- “无权限”的同义词
GRANT OPTION    -- 允许授予权限
```

### 表维护

```
/* 表维护 */
-- 分析和存储表的关键字分布
ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ...
-- 检查一个或多个表是否有错误
CHECK TABLE tbl_name [, tbl_name] ... [option] ...
option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}
-- 整理数据文件的碎片
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...
```

### 杂项

```
/* 杂项 */ ------------------
1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！
2. 每个库目录存在一个保存当前数据库的选项文件db.opt。
3. 注释：
    单行注释 # 注释内容
    多行注释 /* 注释内容 */
    单行注释 -- 注释内容     (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)
4. 模式通配符：
    _   任意单个字符
    %   任意多个字符，甚至包括零字符
    单引号需要进行转义 \'
5. CMD命令行内的语句结束符可以为 ";", "\G", "\g"，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。
6. SQL对大小写不敏感
7. 清除已有语句：\c
```

## 为什么使用索引

1. 可以大大加快 数据的检索速度（大大减少的检索的数据量）, 这也是创建索引的最主要的原因。
2. 将随机IO变为顺序IO
3. 可以加速表和表之间的连接

## 索引的不足

1. 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。
2. 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
3. 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

## MyISAM和InnoDB实现BTree索引方式的区别

myisam ：非聚簇索引

innodb：聚簇索引

## 索引使用的原则

### 最左前缀原则

### 注意避免冗余索引

## Mysql如何为表字段添加索引

1.添加PRIMARY KEY（主键索引）

```
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
```

2.添加UNIQUE(唯一索引)

```
ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 
```

3.添加INDEX(普通索引)

```
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
```

4.添加FULLTEXT(全文索引)

```
ALTER TABLE `table_name` ADD FULLTEXT ( `column`) 
```

5.添加多列索引

```
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```

## 索引类型

### 主键索引(Primary Key)

**数据表的主键列使用的就是主键索引。**

**一张数据表有只能有一个主键，并且主键不能为null，不能重复。**

**在mysql的InnoDB的表中，当没有显示的指定表的主键时，InnoDB会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则InnoDB将会自动创建一个6Byte的自增主键。**

### 二级索引(辅助索引)

**二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。**

唯一索引，普通索引，前缀索引等索引属于二级索引。

1. **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为NULL，一张表允许创建多个唯一索引。**建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
2. **普通索引(Index)** ：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和NULL。**
3. **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
4. **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6之前只有MYISAM引擎支持全文索引，5.6之后InnoDB也支持了全文索引。

![image-20200825195110373](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825195110373.png)

## 聚簇索引和非聚簇索引

**聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**

**非聚集索引即索引结构和数据分开存放的索引。二级索引属于非聚集索引。**

## 覆盖索引使用实例

如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。InnoDB存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”

现在我创建了索引(username,age)，我们执行下面的 sql 语句

```
select username , age from user where username = 'Java' and age = 22
```

在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表。

回表就是通过条件查到对应的主键，然后去表中将列取出

## 索引创建原则

不为null的字段

被频繁查询的字段

被作为条件查询的字段

被频繁链接的字段

## 一条sql语句在mysql中如何执行的

- MySQL 主要分为 Server 层和引擎层，Server 层主要包括**连接器、查询缓存、分析器、优化器、执行器**，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。
- 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。
- 查询语句的执行流程如下：权限校验（如果命中缓存）---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
- 更新语句执行流程如下：分析器----》权限校验----》执行器---》引擎---redo log(prepare 状态---》binlog---》redo log(commit状态)

## 简单介绍一下 Redis 呗!

 **Redis 就是一个使用 C 语言开发的数据库**，不过与传统数据库不同的是 **Redis 的数据是存在内存中的** ，也就是它是内存数据库。另外，**Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。**

## 说一下 Redis 和 Memcached 的区别和共同点

**共同点** ：

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

**区别** ：

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。**
3. **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。
4. **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
5. **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.**
6. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）
7. **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
8. **Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**

## 缓存数据的处理流程是怎样的？

1. 如果用户请求的数据在缓存中就直接返回。
2. 缓存中不存在的话就看数据库中是否存在。
3. 数据库中存在的话就更新缓存中的数据。
4. 数据库中不存在的话就返回空数据。

## 为什么要用 Redis/为什么要用缓存？

假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。

## Redis 常见数据结构以及使用场景分析

**string**：

1. **介绍** ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**（simple dynamic string，**SDS**）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。
2. **常用命令:** `set,get,strlen,exists,dect,incr,setex` 等等。
3. **应用场景** ：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

**list**

1. **介绍** ：**list** 即是 **双向链表**。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
2. **常用命令:** `rpush,lpop,lpush,rpop,lrange、llen` 等。
3. **应用场景:** 发布与订阅或者说消息队列、慢查询。

**hash**

1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。
2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。
3. **应用场景:** 系统中对象数据的存储。

**set**

1. **介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。
2. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。
3. **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

**sorted set**

1. **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。
2. **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。
3. **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

## Redis 单线程模型详解

**Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型** （Netty 的线程模型也基于 Reactor 模式，Reactor 模式是高性能 IO 的基石），这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

**既然是单线程，那怎么监听大量的客户端连接呢？**

Redis 通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。

这样的好处非常明显： **I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗**（和 NIO 中的 `Selector` 组件很像）。

另外， Redis 服务器是一个事件驱动程序，服务器需要处理两类事件： 1. 文件事件; 2. 时间事件。我们接触最多的还是 **文件事件**（客户端进行读取写入等操作，涉及一系列网络通信）。

![image-20200825211202802](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200825211202802.png)

## Redis 没有使用多线程？为什么不使用多线程？

**Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。**

**Redis6.0 之前 为什么不使用多线程？**

我觉得主要原因有下面 3 个：

1. 单线程编程容易并且更容易维护；
2. Redis 的性能瓶颈不再 CPU ，主要在内存和网络；
3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

**Redis6.0 之后为何引入了多线程？**

Redis6.0 引入多线程主要是为了提高网络 IO 读写性能

## Redis 给缓存数据设置过期时间有啥用？

因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接Out of memory。

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效等。

## Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典

## 过期的数据的删除策略？

1. **惰性删除** ：只会在取出key的时候才对数据进行过期检查。这样对CPU最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期key操作。并且，Redis 底层会并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

## Redis 内存淘汰机制了解么？

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least frequently used）**：从已设置**过期**时间的数据集（server.db[i].expires）中挑选最近**最少使用**的数据淘汰
2. **volatile-ttl**：从已设置**过期**时间的数据集（server.db[i].expires）中挑选**将要过期**的数据淘汰
3. **volatile-random**：从已设置**过期**时间的数据集（server.db[i].expires）中**任意**选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近**最少**使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中**任意**选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

## Redis 持久化机制(怎么保证 Redis 挂掉之后再重启数据可以进行恢复)

**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**。

**快照（snapshotting）持久化（RDB）**

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份。

**AOF（append-only file）持久化**

与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化。

为了兼顾数据和写入性能，用户可以考虑 **appendfsync everysec** 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。

## Redis 事务

Redis 可以通过 **MULTI，EXEC，DISCARD 和 WATCH** 等命令来实现事务(transaction)功能。**Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。Redis事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。**

## 缓存穿透

**什么是缓存穿透**

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

**缓存穿透的处理流程**

![image-20200826091448833](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826091448833.png)

**解决办法**

**缓存无效key**，假如黑客使用的相近的key，可以使用这种方式。

**布隆过滤器**，布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。

## 缓存雪崩

**缓存雪崩**，缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。

举个例子 ：秒杀开始 12 个小时之前，我们统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 12 个小时，那么秒杀开始的时候，这些秒杀的商品的访问直接就失效了。导致的情况就是，相应的请求直接就落到了数据库上，就像雪崩一样可怕。

**解决办法**

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

## 如何保证缓存与数据库双写时的数据一致性?

下面单独对 **Cache Aside Pattern（旁路缓存模式）** 来聊聊。

Cache Aside Pattern 中遇到写请求是这样的：更新 DB，然后直接删除 cache 。

如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：

1. **缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
2. **增加cache更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。

## Redis 的优点

快

支持丰富的数据类型

操作具有原子性

## Redis 的五种数据类型

**String**

Redis 中的字符串是一种 **动态字符串，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。**

不适用c存储的原因：字符串长度不容易获取，不能杜绝内存泄漏，只能保存文本	

基本操作：

**list**

Redis 的列表相当于 Java 语言中的 **LinkedList**，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。

基本操作：

- `LPUSH` 和 `RPUSH` 分别可以向 list 的左边（头部）和右边（尾部）添加一个新元素；
- `LRANGE` 命令可以从 list 中取出一定范围的元素；
- `LINDEX` 命令可以从 list 中取出指定下表的元素，相当于 Java 链表操作中的 `get(int index)` 操作；

**Hash**

Redis 中的字典相当于 Java 中的 **HashMap**，内部实现也差不多类似，都是通过 **"数组 + 链表"** 的链地址法来解决部分 **哈希冲突**

扩容：正常情况下，当 hash 表中 **元素的个数等于第一维数组的长度时**，就会开始扩容，扩容的新数组是 **原数组大小的 2 倍**。不过如果 Redis 正在做 `bgsave(持久化命令)`，为了减少内存也得过多分离，Redis 尽量不去扩容，但是如果 hash 表非常满了，**达到了第一维数组长度的 5 倍了**，这个时候就会 **强制扩容**。

**set**

Redis 的集合相当于 Java 语言中的 **HashSet**，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL。

**zset**

内部实现用的是一种叫做 **「跳跃表」** 的数据结构

## HyperLogLog 

**基数**

基数就是指一个集合中不同值的数目，比如[a,b,c,d]的基数就是4，[a,b,c,d,a]的基数还是4，因为a重复了一个。

**分桶**

最简单的一种优化方法显然就是把数据分成m个均等的部分，分别估计其总数求平均后再乘以m，称之为分桶。

![image-20200826105116481](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826105116481.png)

**调和平均数**

一个常见的例子是，假如我的工资是1000元一个月，我老板的工资是100000元一个月，那么我和老板的平均工资就是(100000 + 1000)/2，即50500元，用调和平均数就可以解决这一问题，调和平均数的结果会倾向于集合中比较小的数。

**细节微调**

**常数的选择**：constant常数的选择与分桶的数目有关

**分桶数**：如果理解了之前的分桶算法，那么很显然分桶数只能是2的整数次幂。如果分桶越多，那么估计的精度就会越高。

**合并**：假设有两个数据流，分别构建了两个HyperLogLog结构，称为a和b，他们的桶数是一样的，为n，现在要计算两个数据流总体的基数。这就是合并。

**使用**：pfadd 和 pfcount

## 布隆过滤器

**场景**：大数据判断是否存在，解决缓存穿透，系统过滤

**使用**：bf.add 和bf.exists

**参数**：

- **`error_rate` 越低，需要的空间越大**，对于不需要过于精确的场合，设置稍大一些也没有关系，比如上面说的推送系统，只会让一小部分的内容被过滤掉，整体的观看体验还是不会受到很大影响的；
- **`initial_size` 表示预计放入的元素数量**，当实际数量超过这个值时，误判率就会提升，所以需要提前设置一个较大的数值避免超出导致误判率升高；

## GeoHash

用于 **地理位置距离排序** 的一个算法，**Redis** 也采用了这样的算法。GeoHash 算法将 **二维的经纬度** 数据映射到 **一维** 的整数，这样所有的元素都将在挂载到一条线上，它的核心思想就是把整个地球看成是一个 **二维的平面**，然后把这个平面不断地等分成一个一个小的方格，**每一个** 坐标元素都位于其中的 **唯一一个方格** 中，等分之后的 **方格越小**，那么坐标也就 **越精确**

**使用**：

geoadd 增加

geodist 距离

geopos 元素的位置

georadiusbymember 附近的

**注意事项**

在一个地图应用中，车的数据、餐馆的数据、人的数据可能会有百万千万条，如果使用 **Redis** 的 **Geo** 数据结构，它们将 **全部放在一个** zset 集合中。在 **Redis** 的集群环境中，集合可能会从一个节点迁移到另一个节点，如果单个 key 的数据过大，会对集群的迁移工作造成较大的影响，在集群环境中单个 key 对应的数据量不宜超过 1M，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。

所以，这里建议 **Geo** 的数据使用 **单独的 Redis 实例部署**，不使用集群环境。

如果数据量过亿甚至更大，就需要对 **Geo** 数据进行拆分，按国家拆分、按省拆分，按市拆分，在人口特大城市甚至可以按区拆分。这样就可以显著降低单个 zset 集合的大小。

## 分布式锁的简介

**锁** 是一种用来解决多个执行线程 **访问共享资源** 错误或数据不一致问题的工具。

## 锁的常见方式

1. **基于 MySQL 中的锁**：MySQL 本身有自带的悲观锁 `for update` 关键字，也可以自己实现悲观/乐观锁来达到目的；
2. **基于 Zookeeper 有序节点**：Zookeeper 允许临时创建有序的子节点，这样客户端获取节点列表时，就能够当前子节点列表中的序号判断是否能够获得锁；
3. **基于 Redis 的单线程**：由于 Redis 是单线程，所以命令会以串行的方式执行，并且本身提供了像 `SETNX(set if not exists)` 这样的指令，本身具有互斥性；

## redis持久化发生了什么（从内存到硬盘）

1. 客户端向数据库 **发送写命令** *(数据在客户端的内存中)*
2. 数据库 **接收** 到客户端的 **写请求** *(数据在服务器的内存中)*
3. 数据库 **调用系统 API** 将数据写入磁盘 *(数据在内核缓冲区中)*
4. 操作系统将 **写缓冲区** 传输到 **磁盘控控制器** *(数据在磁盘缓存中)*
5. 操作系统的磁盘控制器将数据 **写入实际的物理媒介** 中 *(数据在磁盘中)*

## 快照方式持久化

但我们知道，Redis 是一个 **单线程** 的程序，这意味着，我们不仅仅要响应用户的请求，还需要进行内存快照。而后者要求 Redis 必须进行 IO 操作，这会严重拖累服务器的性能。

还有一个重要的问题是，我们在 **持久化的同时**，**内存数据结构** 还可能在 **变化**，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它删除了，可是这才刚持久化结束。

方案：操作系统多进程 **COW(Copy On Write) 机制** 拯救了我们。**Redis** 在持久化时会调用 `glibc` 的函数 `fork` 产生一个子进程，简单理解也就是基于当前进程 **复制** 了一个进程，所以 **快照持久化** 可以完全交给 **子进程** 来处理，**父进程** 则继续 **处理客户端请求**。**子进程** 做数据持久化，它 **不会修改现有的内存数据结构**，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是 **父进程** 不一样，它必须持续服务客户端请求，然后对 **内存数据结构进行不间断的修改**。

## 追加持久化方式

**AOF(Append Only File - 仅追加文件)** 它的工作方式非常简单：每次执行 **修改内存** 中数据集的写操作时，都会 **记录** 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 **所有的修改性指令序列**，那么就可以通过对一个空的 Redis 实例 **顺序执行所有的指令**，也就是 **「重放」**，来恢复 Redis 当前实例的内存数据结构的状态。

### aof 瘦身

**Redis** 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 **AOF 日志 "瘦身"**。

**Redis** 提供了 `bgrewriteaof` 指令用于对 AOF 日志进行瘦身。其 **原理** 就是 **开辟一个子进程** 对内存进行 **遍历** 转换成一系列 Redis 的操作指令，**序列化到一个新的 AOF 日志文件** 中。序列化完毕后再将操作期间发生的 **增量 AOF 日志** 追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。

## REST 接口规范

- GET ：请求从服务器获取特定资源。举个例子：`GET /classes`（获取所有班级）
- POST ：在服务器上创建一个新的资源。举个例子：`POST /classes`（创建班级）
- PUT ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：`PUT /classes/12`（更新编号为 12 的班级）
- DELETE ：从服务器删除特定的资源。举个例子：`DELETE /classes/12`（删除编号为 12 的班级）
- PATCH ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少，这里就不举例子了。

## 状态码

| 2xx：成功 | 3xx：重定向    | 4xx：客户端错误  | 5xx：服务器错误 |
| --------- | -------------- | ---------------- | --------------- |
| 200 成功  | 301 永久重定向 | 400 错误请求     | 500 服务器错误  |
| 201 创建  | 304 资源未修改 | 401 未授权       | 502 网关错误    |
|           |                | 403 禁止访问     | 504 网关超时    |
|           |                | 404 未找到       |                 |
|           |                | 405 请求方法不对 |                 |

## 常见的命名规则

**驼峰式**

大驼峰式（ServiceDiscovery、ServiceInstance、LruCacheFactory）

小驼峰式（getUserInfo()、createCustomThreadPool()、setNameFormat(String nameFormat)）

**蛇形命名法**（should_get_200_status_code_when_request_is_valid）

**串式命名法**（kebab-case）

## java命名规范

**1.类名需要使用大驼峰命名法（UpperCamelCase）风格。方法名、参数名、成员变量、局部变量需要使用小驼峰命名法（lowerCamelCase）。**

**2.测试方法名、常量、枚举名称需要使用蛇形命名法（snake_case）**，比如`should_get_200_status_code_when_request_is_valid`、`CLIENT_CONNECT_SERVER_FAILURE`。并且，**测试方法名称要求全部小写，常量以及枚举名称需要全部大写。**

**3.项目文件夹名称使用串式命名法（kebab-case），比如`dubbo-registry`。**

**4.包名统一使用小写，尽量使用单个名词作为包名，各个单词通过 "." 分隔符连接，并且各个单词必须为单数。**

正例： `org.apache.dubbo.common.threadlocal`

反例： ~~`org.apache.dubbo.common.threadLocal`~~

**5.抽象类命名使用 Abstract 开头**。

**6.异常类命名使用 Exception 结尾。**

**7.测试类命名以它要测试的类的名称开始，以 Test 结尾。**

## spring 框架

Spring 是一种轻量级开发框架，旨在提高开发人员的**开发效率**以及系统的**可维护性**。

- **核心技术** ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。
- **测试** ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。
- **数据访问** ：事务，DAO支持，JDBC，ORM，编组XML。
- **Web支持** : Spring MVC和Spring WebFlux Web框架。
- **集成** ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。
- **语言** ：Kotlin，Groovy，动态语言。

## spring 模块

![image-20200826195221159](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826195221159.png)

### @RestController vs @Controller

@Controller 返回一个view

@RestController 返回json 和xml

@Controller + @ResponseBody 返回json 和 xml

### ioc

![image-20200826200229157](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826200229157.png)

### aop

能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。**Spring AOP就是基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用**Cglib** ，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理。

**Advice(通知)**:AOP在特定的切入点上执行的增强处理，有before(前置),after(后置),afterReturning(最终),afterThrowing(异常),around(环绕)

**Pointcut(切入点)**:就是带有通知的连接点，在程序中主要体现为书写切入点**表达式**

**Aspect(切面)**:通常是一个类，里面可以定义**切入点和通知**

**目标对象（Target Object）**: 包含连接点的对象。也被称作被通知或被代理对象。POJO

**weave(织入)**：将切面应用到目标对象并导致**代理对象创建**的过程

**AOP代理(AOP Proxy)**：AOP框架创建的对象，代理就是目标对象的加强。Spring中的AOP代理可以使JDK动态代理，也可以是CGLIB代理，前者基于接口，后者基于子类

**introduction(引入)**：在不修改代码的前提下，引入可以在**运行期**为类动态地添加一些方法或字段

**JointPoint(连接点)**:程序执行过程中明确的点，一般是**方法**的调用。被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
">

    <!-- 定义被代理者 -->
    <bean id="h1" class="com.lym.aopTest.HelloWorldImpl1"></bean>
    <bean id="h2" class="com.lym.aopTest.HelloWorldImpl2"></bean>

    <!-- 定义通知内容，也就是切入点执行前后需要做的事情 -->
    <bean id="timeHandler" class="com.lym.aopTest.TimeHandler"></bean>

    <!-- 定义切入点位置，这里定义到了doPrint方法上 -->
    <bean id="timePointcut" class="org.springframework.aop.support.JdkRegexpMethodPointcut">
        <property name="pattern" value=".*doPrint"></property>
    </bean>

    <!-- 使切入点与通知相关联，完成切面配置 -->
    <bean id="timeHandlerAdvisor" class="org.springframework.aop.support.DefaultPointcutAdvisor">
        <property name="advice" ref="timeHandler"></property>
        <property name="pointcut" ref="timePointcut"></property>
    </bean>

    <!-- 设置代理 -->
    <bean id="proxy" class="org.springframework.aop.framework.ProxyFactoryBean">
        <!-- 代理的对象，有打印时间能力 -->
        <property name="target" ref="h1"></property>
        <!-- 使用切面 -->
        <property name="interceptorNames" value="timeHandlerAdvisor"></property>
        <!-- 代理接口，hw接口 -->
        <property name="proxyInterfaces" value="com.lym.aopTest.HelloWorld"></property>
    </bean>
    <!-- 设置代理 -->
    <bean id="proxy2" class="org.springframework.aop.framework.ProxyFactoryBean">
        <!-- 代理的对象，有打印时间能力 -->
        <property name="target" ref="h2"></property>
        <!-- 使用切面 -->
        <property name="interceptorNames" value="timeHandlerAdvisor"></property>
        <!-- 代理接口，hw接口 -->
        <property name="proxyInterfaces" value="com.lym.aopTest.HelloWorld"></property>
    </bean>

   <!--<bean class="org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator"/>-->

</beans>
```

### Spring AOP 和 AspectJ AOP 区别

**Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。** Spring AOP **基于代理**(Proxying)，而 AspectJ 基于**字节码操作**(Bytecode Manipulation)。

AspectJ 相比于 Spring AOP **功能更加强大**，但是 Spring AOP 相对来说更**简单**，如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。

## spring bean

### bean 的作用域

singleton（单例）

prototype（每次请求都创建一个新的实例）

request （每次请求都产生一个新的bean，当且仅当本request 有效）

session（每次请求都会产生一个bean，当且仅当session 有效）

### 单例bean 线程安全

类中定义一个ThreadLocal 成员变量

### @Component 和 @Bean 的区别

1. 作用对象不同: `@Component` 注解作用于**类**，而`@Bean`注解作用于方法。
2. `@Component`通常是通过**类路径扫描**来自动侦测以及自动装配到Spring容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在**标有该注解的方法**中定义产生这个 bean,`@Bean`告诉了Spring这是某个类的示例，当我需要用它的时候还给我。
3. `@Bean` 注解比 `Component` 注解的**自定义性更强**，而且很多地方我们只能通过 `@Bean` 注解来注册bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。

### 将一个类声明为spring 的bean 的注解

我们一般使用 `@Autowired` 注解自动装配 bean（修饰属性）,采用以下注解可实现：

- `@Component` （修饰类）：通用的注解，可标注任意类为 `Spring` 组件。如果一个Bean不知道属于哪个层，可以使用`@Component` 注解标注。
- `@Repository` （修饰类）: 对应持久层即 Dao 层，主要用于数据库相关操作。
- `@Service`（修饰类） : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。
- `@Controller` （修饰类）: 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。

### spring 的生命周期

**1.实现InitializingBean和DisposableBean接口**

这两个接口都只包含一个方法。通过实现InitializingBean接口的afterPropertiesSet()方法可以在Bean属性值设置好之后做一些操作，实现DisposableBean接口的destroy()方法可以在销毁Bean之前做一些操作。

**2.在bean的配置文件中指定init-method和destroy-method方法**

Spring允许我们创建自己的init方法和destroy方法，只要在Bean的配置文件中指定init-method和destroy-method的值就可以在Bean初始化时和销毁之前执行一些操作。

**3.使用@PostConstruct和@PreDestroy注解**

除了xml配置的方式，Spring也支持用`@PostConstruct`和 `@PreDestroy`注解来指定init和destroy方法。这两个注解均在`javax.annotation`包中。
为了注解可以生效，需要在配置文件中定义`org.springframework.context.annotation.CommonAnnotationBeanPostProcessor`或`context:annotation-config`

### 总结

所以。。。结合第一节控制台输出的内容，Spring Bean的生命周期是这样纸的：

- Bean容器找到配置文件中Spring Bean的定义。
- Bean容器利用Java Reflection API创建一个Bean的实例。
- 如果涉及到一些属性值 利用set方法设置一些属性值。
- 如果Bean实现了BeanNameAware接口，调用setBeanName()方法，传入Bean的名字。
- 如果Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。
- 如果Bean实现了BeanFactoryAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。
- 与上面的类似，如果实现了其他*Aware接口，就调用相应的方法。
- 如果有和加载这个Bean的Spring容器相关的BeanPostProcessor对象，执行postProcessBeforeInitialization()方法
- 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。
- 如果Bean在配置文件中的定义包含`init-method`属性，执行指定的方法。
- 如果有和加载这个Bean的Spring容器相关的BeanPostProcessor对象，执行postProcessAfterInitialization()方法
- 当要销毁Bean的时候，如果Bean实现了DisposableBean接口，执行destroy()方法。
- 当要销毁Bean的时候，如果Bean在配置文件中的定义包含`destroy-method`属性，执行指定的方法。

## spring mvc

### mvc

早期，bean+jjsp+servlet

MVC 是一种设计模式,Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的Web层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service层（处理业务）、Dao层（数据库操作）、Entity层（实体类）、Controller层(控制层，返回数据给前台页面)。

![image-20200826215655940](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826215655940.png)

### spring mvc 工作原理

![image-20200826215823674](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200826215823674.png)

**流程说明（重要）：**

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）

## spring 事务

1. 编程式事务，在代码中硬编码。(不推荐使用)
2. 声明式事务，在配置文件中配置（推荐使用）

**声明式事务又分为两种：**

1. 基于XML的声明式事务
2. 基于注解的声明式事务

### 事务中的隔离级别

TransactionDefination 接口中定义的5个表示隔离级别的常量

- **TransactionDefinition.ISOLATION_DEFAULT:** 使用后端数据库默认的隔离级别，Mysql 默认采用的 **REPEATABLE_READ**隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
- **TransactionDefinition.ISOLATION_READ_UNCOMMITTED:** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**
- **TransactionDefinition.ISOLATION_READ_COMMITTED:** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**
- **TransactionDefinition.ISOLATION_REPEATABLE_READ:** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**
- **TransactionDefinition.ISOLATION_SERIALIZABLE:** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

### 事务的传播行为

**支持当前事务的情况：**

- **TransactionDefinition.PROPAGATION_REQUIRED（要求）：** 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。
- **TransactionDefinition.PROPAGATION_SUPPORTS（支持）：** 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。
- **TransactionDefinition.PROPAGATION_MANDATORY（强制）：** 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

**不支持当前事务的情况：**

- **TransactionDefinition.PROPAGATION_REQUIRES_NEW（要求新）：** 创建一个新的事务，如果当前存在事务，则把当前事务挂起。
- **TransactionDefinition.PROPAGATION_NOT_SUPPORTED（不支持）：** 以非事务方式运行，如果当前存在事务，则把当前事务挂起。
- **TransactionDefinition.PROPAGATION_NEVER（永不）：** 以非事务方式运行，如果当前存在事务，则抛出异常。

### @Transaction（rollbackFor=Exception.class）

在`@Transactional`注解中如果不配置`rollbackFor`属性,那么事物只会在遇到`RuntimeException`的时候才会回滚,加上`rollbackFor=Exception.class`,可以让事物在遇到非运行时异常时也回滚。

## lombok 

以前的Java项目中，充斥着太多不友好的代码：POJO的getter/setter/toString；异常处理；I/O流的关闭操作等等，这些样板代码既没有技术含量，又影响着代码的美观，Lombok应运而生。

**@Getter/@Setter: 作用类上，生成所有成员变量的getter/setter方法；作用于成员变量上，生成该成员变量的getter/setter方法。可以设定访问权限及是否懒加载等。**

**@ToString：作用于类，覆盖默认的toString()方法，可以通过of属性限定显示某些字段，通过exclude属性排除某些字段。**

**@EqualsAndHashCode：作用于类，覆盖默认的equals和hashCode**

**@NonNull：主要作用于成员变量和参数中，标识不能为空，否则抛出空指针异常。**

**@NoArgsConstructor：生成无参构造器；**

**@RequiredArgsConstructor：生成包含final和@NonNull注解的成员变量的构造器；**

**@AllArgsConstructor：生成全参构造器**

**@Data：作用于类上，是以下注解的集合：@ToString @EqualsAndHashCode @Getter @Setter @RequiredArgsConstructor
**

**@Builder：作用于类上，将类转变为建造者模式**

**@Log：作用于类上，生成日志变量。针对不同的日志实现产品，有不同的注解**

## SpringBoot

spring 组件是轻量级的，但是配置确实重量级的，Spring Boot就是Spring，它做了那些没有它你自己也会去做的Spring Bean配置。

### 配置信息

**通过`@ConfigurationProperties`读取并与 bean 绑定**

```
@ConfigurationProperties(prefix = "library")
```

### `@PropertySource`读取指定 properties 文件

```
@PropertySource("classpath:website.properties")
```

### @SpringBootApplication 注解

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
- `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的bean，注解默认会扫描该类所在的包下所有的类。
- `@Configuration`：允许在上下文中注册额外的bean或导入其他配置类。

### RESTful Web 服务

**传统的 MVC 模式开发会直接返回给客户端一个视图，但是 RESTful Web 服务一般会将返回的数据以 JSON 的形式返回，这也就是现在所推崇的前后端分离开发。**

### @PostConstruct 和 @PreDestroy

**被这两个注解修饰的方法可以保证在整个 Servlet 生命周期只被执行一次。**@PostConstruct 修饰方法，在构造函数之后执行，servlet 得init() 之前进行。@PreDestroy 会在servlet 得destory（）方法之前执行。

### 使用 @ControllerAdvice和**@ExceptionHandler处理全局异常

@ControllerAdvice 注解，可以用于定义@ExceptionHandler、@InitBinder、@ModelAttribute，并应用到所有@RequestMapping中。

### jpa

**配置**：`spring.jpa.hibernate.ddl-auto=create`这个配置选项。

这个属性常用的选项有四种：

1. `create`:每次重新启动项目都会重新创新表结构，会导致数据丢失
2. `create-drop`:每次启动项目创建表结构，关闭项目删除表结构
3. `update`:每次启动项目会更新表结构
4. `validate`:验证表结构，不对数据库进行任何更改

**增删查改**：

savaAndFlush（） deleteById（） findById（） 

自定义sql：@Query（""）

创建异步方法：@Async

### 过滤器

**手动实现**

```
@Component
public class MyFilter implements Filter {
    private static final Logger logger = LoggerFactory.getLogger(MyFilter.class);

    @Override
    public void init(FilterConfig filterConfig) {
        logger.info("初始化过滤器：", filterConfig.getFilterName());
    }

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        //对请求进行预处理
        logger.info("过滤器开始对请求进行预处理：");
        HttpServletRequest request = (HttpServletRequest) servletRequest;
        String requestUri = request.getRequestURI();
        System.out.println("请求的接口为：" + requestUri);
        long startTime = System.currentTimeMillis();
        //通过 doFilter 方法实现过滤功能
        filterChain.doFilter(servletRequest, servletResponse);
        // 上面的 doFilter 方法执行结束后用户的请求已经返回
        long endTime = System.currentTimeMillis();
        System.out.println("该用户的请求已经处理完毕，请求花费的时间为：" + (endTime - startTime));
    }

    @Override
    public void destroy() {
        logger.info("销毁过滤器");
    }
}
```

**配置**

```
@Configuration
public class MyFilterConfig {
    @Autowired
    MyFilter myFilter;
    @Bean
    public FilterRegistrationBean<MyFilter> thirdFilter() {
        FilterRegistrationBean<MyFilter> filterRegistrationBean = new FilterRegistrationBean<>();

        filterRegistrationBean.setFilter(myFilter);

        filterRegistrationBean.setUrlPatterns(new ArrayList<>(Arrays.asList("/api/*")));

        return filterRegistrationBean;
    }
}
```

**注解**

```
@WebFilter(filterName = "MyFilterWithAnnotation", urlPatterns = "/api/*")
public class MyFilterWithAnnotation implements Filter {

   ......
}
```

### 拦截器

- 过滤器（Filter）：当你有一堆东西的时候，你只希望选择符合你要求的某一些东西。定义这些要求的工具，就是过滤器。
- 拦截器（Interceptor）：在一个流程正在进行的时候，你希望干预它的进展，甚至终止它进行，这是拦截器做的事情。

### BeanUtils

![image-20200828094653071](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200828094653071.png)

使用`org.apache.commons.beanutils.BeanUtils`对复杂对象的复制是引用，这是一种**浅拷贝**,但是由于 Apache下的BeanUtils对象拷贝性能太差，不建议使用。

commons-beantutils 对于对象拷贝加了很多的检验，包括类型的转换，甚至还会检验对象所属的类的可访问性,可谓相当复杂，这也造就了它的差劲的性能。

使用spring的BeanUtils进行对象拷贝，实现方式非常简单，就是对两个对象中相同名字的属性进行简单的get/set，仅检查属性的可访问性。

### bean 映射框架

**Dozer** 是一个映射框架，它使用递归将数据从一个对象复制到另一个对象。框架不仅能够在 bean 之间复制属性，还能够在不同类型（不同类）之间自动转换。

**Orika** 是一个 bean 到 bean 的映射框架，它递归地将数据从一个对象复制到另一个对象。Orika 的工作原理与 Dozer 相似。两者之间的主要区别是 Orika 使用字节码生成。这允许以最小的开销生成更快的映射器。

**MapStruct** 是一个自动生成 bean mapper 类的代码生成器。MapStruct 还能够在不同的数据类型之间进行转换。

**ModelMapper** 是一个旨在简化对象映射的框架，它根据约定确定对象之间的映射方式。它提供了类型安全的和重构安全的 API。

**JMapper** 是一个映射框架，旨在提供易于使用的、高性能的 Java bean 之间的映射。该框架旨在使用注释和关系映射应用 DRY 原则。该框架允许不同的配置方式:基于注释、XML 或基于 api。

### springboot 参数校验

使用 Spring Boot 程序的话只需要`spring-boot-starter-web` 就够了

**jsr提供的注解**

- `@Null` 被注释的元素必须为 null
- `@NotNull` 被注释的元素必须不为 null
- `@AssertTrue` 被注释的元素必须为 true
- `@AssertFalse` 被注释的元素必须为 false
- `@Min(value) `被注释的元素必须是一个数字，其值必须大于等于指定的最小值
- `@Max(value) `被注释的元素必须是一个数字，其值必须小于等于指定的最大值
- `@DecimalMin(value) `被注释的元素必须是一个数字，其值必须大于等于指定的最小值
- `@DecimalMax(value)` 被注释的元素必须是一个数字，其值必须小于等于指定的最大值
- `@Size(max=, min=) `被注释的元素的大小必须在指定的范围内
- `@Digits (integer, fraction) `被注释的元素必须是一个数字，其值必须在可接受的范围内
- `@Past `被注释的元素必须是一个过去的日期
- `@Future` 被注释的元素必须是一个将来的日期
- `@Pattern(regex=,flag=) `被注释的元素必须符合指定的正则表达式

**Hibernate Validator提供的校验注解**：

- `@NotBlank(message =) `验证字符串非null，且长度必须大于0
- `@Email` 被注释的元素必须是电子邮箱地址
- `@Length(min=,max=) `被注释的字符串的大小必须在指定的范围内
- `@NotEmpty `被注释的字符串的必须非空
- `@Range(min=,max=,message=)` 被注释的元素必须在合适的范围内

**@NotNull vs @Column（nullable=false)**

- `@NotNull`是 JSR 303 Bean验证批注,它与数据库约束本身无关。
- `@Column(nullable = false)` : 是JPA声明列为非空的方法。

### spring schedule 实现定时任务

```
@Scheduled(fixedRate = 5000)// 每五秒执行一次

@EnableScheduling  // 在启动类上加

@EnableAsync 和 @Async //使定时任务并行执行
```

### Spring Boot 异步编程

**Future 模式**

Future 模式的核心思想是 **异步调用** 。当我们执行一个方法时，假如这个方法中有多个耗时的任务需要同时去做，而且又不着急等待这个结果时可以让客户端立即返回然后，后台慢慢去计算任务。当然你也可以选择等这些任务都执行完了，再返回给客户端。这个在 Java 中都有很好的支持。

如果我们需要在 SpringBoot **实现异步编程**的话，通过 Spring 提供的两个注解会让这件事情变的非常简单。

1. `@EnableAsync`：通过在配置类或者Main类上加@EnableAsync开启对异步方法的支持。
2. `@Async` 可以作用在类上或者方法上，作用在类上代表这个类的所有方法都是异步方法。

**应用场景**

另外，**从上面的运行结果可以看出，当所有任务执行完成之后才返回结果。这种情况对应于我们需要返回结果给客户端请求的情况下，假如我们不需要返回任务执行结果给客户端的话呢？** 就比如我们上传一个大文件到系统，上传之后只要大文件格式符合要求我们就上传成功。普通情况下我们需要等待文件上传完毕再返回给用户消息，但是这样会很慢。采用异步的话，当用户上传之后就立马返回给用户消息，然后系统再默默去处理上传任务。**这样也会增加一点麻烦，因为文件可能会上传失败，所以系统也需要一点机制来补偿这个问题，比如当上传遇到问题的时候，发消息通知用户。**

### kafka

1. **极致的性能** ：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌** ：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

流平台具有三个关键功能：

1. **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2. **容错的持久方式存储记录消息流**： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险·。
3. **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

Kafka 主要有两大应用场景：

1. **消息队列** ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
2. **数据处理：** 构建实时的流数据处理程序来转换或处理数据流。

### SpringBoot+Dubbo 搭建一个简单分布式服务

Apache **Dubbo** (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。简单来说 Dubbo 是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。

**什么是 RPC？**

RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。比如两个不同的服务A,B部署在两台不同的机器上，那么服务 A 如果想要调用服务 B 中的某个方法该怎么办呢？使用 HTTP请求 当然可以，但是可能会比较慢而且一些优化做的并不好。 RPC 的出现就是为了解决这个问题。

**为什么要用 Dubbo？**

如果你要开发分布式程序，你也可以直接基于 HTTP 接口进行通信，但是为什么要用 Dubbo呢？

我觉得主要可以从 Dubbo 提供的下面四点特性来说为什么要用 Dubbo：

1. **负载均衡**——同一个服务部署在不同的机器时该调用那一台机器上的服务
2. **服务调用链路生成**——服务之间互相是如何调用的
3. **服务访问压力以及时长统计**——当前系统的压力主要在哪里，如何来扩容和优化
4. **服务降级**——某个服务挂掉之后调用备用服务

## mybatis

### #{} 和 #{} 的区别

Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的

`#`  将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #{user_id}，如果传入的值是 name , 那么解析成sql时的值为order by “name”, 如果传入的值是id，则解析成的sql为order by “id”.

`$`  将传入的数据直接显示生成在sql中。如：order by ${user_id}，如果传入的值是name, 那么解析成sql时的值为order by name, 如果传入的值是id，则解析成的sql为order by id.

### Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？

resultmap parametermap sql include

trim where set foreach if choose when otherwise bind

### 最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？

Dao 接口，就是人们常说的 `Mapper`接口，接口的**全限名**，就是映射文件中的 **namespace** 的值，接口的**方法名**，就是映射文件中`MappedStatement`的 **id 值**，接口方法内的**参数**，就是传递给 **sql 的参数**。`Mapper`接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个`MappedStatement`。

Dao 接口里的方法，是**不能重载**的，因为是全限名+方法名的保存和寻找策略。

Dao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 **proxy 对象**，代理对象 proxy 会拦截接口方法，转而执行`MappedStatement`所代表的 sql，然后将 sql 执行结果返回。

### Mybatis 是如何进行分页的？分页插件的原理是什么？

Mybatis 使用 **RowBounds** 对象进行分页，它是针对 **ResultSet** 结果集执行的内存分页，而是**逻辑分页**，可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。

分页插件的基本原理是使用 Mybatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。

**逻辑分页和物理分页**

物理分页指的是用limit 关键字，数据库返回的直接就是分页的结果

逻辑分页，数据库返回全部数据，由程序员通过代码获取分页数据

### Mybatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？

第一种是使用`<resultMap>`标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，Mybatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，Mybatis 一样可以正常工作。

有了列名与属性名的映射关系后，Mybatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。

### mybatis 支持延迟加载

Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。它的原理是，使用 CGLIB 创建目标对象的**代理对象**，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。当然了，不光是 Mybatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。

### Mybatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？

不同的 Xml 映射文件，如果配置了 **namespace**，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复；

原因就是 namespace+id 是作为 `Map<String, MappedStatement>`的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。

### Mybatis 中如何执行批处理？

使用 BatchExecutor 完成批处理。

### Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？

Mybatis 有三种基本的 Executor 执行器，**`SimpleExecutor`、`ReuseExecutor`、`BatchExecutor`。**

**`SimpleExecutor`：**每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。

**`ReuseExecutor`：**执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map<String, Statement>内，供下一次使用。简言之，就是重复使用 Statement 对象。

**`BatchExecutor`：**执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。

### Mybatis 是否可以映射 Enum 枚举类？

Mybatis **可以**映射枚举类，Mybatis 可以映射任何对象到表的一列上。映射方式为自定义一个 `TypeHandler`，实现 `TypeHandler` 的 `setParameter()`和 `getResult()`接口方法。`TypeHandler` 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 `setParameter()`和 `getResult()`两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。

### Mybatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？

虽然 Mybatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。

原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为**未解析**状态，然后继续解析余下的标签，包含 B 标签，待所有**标签解析**完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。

### 简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？

Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中，`<parameterMap>`标签会被解析为 `ParameterMap` 对象，其每个子元素会被解析为 ParameterMapping 对象。`<resultMap>`标签会被解析为 `ResultMap` 对象，其每个子元素会被解析为 `ResultMapping` 对象。每一个`<select>、<insert>、<update>、<delete>`标签均会被解析为 `MappedStatement` 对象，标签内的 sql 会被解析为 BoundSql 对象。

### 为什么说 Mybatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？

Hibernate 属于**全自动** ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 Mybatis 在查询关联对象或关联集合对象时，需要**手动编写 sql** 来完成，所以，称之为半自动 ORM 映射工具。

面试题看似都很简单，但是想要能正确回答上来，必定是研究过源码且深入的人，而不是仅会使用的人或者用的很熟的人，以上所有面试题及其答案所涉及的内容，在我的 Mybatis 系列博客中都有详细讲解和原理分析。

## 认证和授权

- **Authentication（认证）** 是验证您的身份的凭据（例如用户名/用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统存在你这个用户。所以，Authentication 被称为身份/用户验证。
- **Authorization（授权）** 发生在 **Authentication（认证）** 之后。授权嘛，光看意思大家应该就明白，它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。

### cookie

1. 我们在 Cookie 中保存已经登录过的用户信息
2. 使用Cookie 保存 session 或者 token ，向后端发送请求的时候带上 Cookie，这样后端就能取到session或者token了。这样就能记录用户当前的状态了
3. Cookie 还可以用来记录和分析用户行为。举个简单的例子你在网上购物的时候，因为HTTP协议是没有状态的，如果服务器想要获取你在某个页面的停留状态或者看了哪些商品，一种常用的实现方式就是将这些信息存放在Cookie

```java
@GetMapping("/change-username")
public String setCookie(HttpServletResponse response) {
    // 创建一个 cookie
    Cookie cookie = new Cookie("username", "Jovan");
    //设置 cookie过期时间
    cookie.setMaxAge(7 * 24 * 60 * 60); // expires in 7 days
    //添加到 response 中
    response.addCookie(cookie);

    return "Username is changed!";
}
```

```java
@GetMapping("/")
public String readCookie(@CookieValue(value = "username", defaultValue = "Atta") String username) {
    return "Hey! My username is " + username;
}
```

### Cookie 和 Session 有什么区别？如何使用Session进行身份验证？

**Session 的主要作用就是通过服务端记录用户的状态。Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。**

![image-20200828200205673](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200828200205673.png)

1. 用户向服务器发送用户名和密码用于**登陆**系统。
2. 服务器验证通过后，服务器为用户创建一个 **Session**，并将 Session信息存储起来。
3. 服务器向用户返回一个 **SessionID**，写入用户的 Cookie。
4. 当用户保持登录状态时，Cookie 将与每个后续请求一起被发送出去。
5. 服务器可以将存储在 Cookie 上的 Session ID 与存储在内存中或者数据库中的 Session 信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带用户当前的状态。

注意：session 的业务必须要客户端开启了cookie，cookie的过期时间

### cookie 和token

**cookie**:小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。

**token**，我们使用 token 的话就不会存在这个问题，在我们登录成功获得 token 之后，一般会选择存放在 local storage 中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 token 的，所以这个请求将是非法的。

**注意**的是不论是 Cookie 还是 token 都无法避免跨站脚本攻击（Cross Site Scripting）XSS。

### 什么是 Token?什么是 JWT?如何基于Token进行身份验证？

session 需要将信息保存到服务端，带来麻烦。JWT （JSON Web Token） 就是这种方式的实现，通过这种方式服务器端就不需要保存 Session 数据了，只用在客户端保存服务端返回给客户的 Token 就可以了，扩展性得到提升。**JWT 本质上就一段签名的 JSON 格式的数据。由于它是带有签名的，因此接收者便可以验证它的真实性。**

JWT 由 3 部分构成:

1. Header :描述 JWT 的元数据。定义了生成签名的算法以及 Token 的类型。
2. Payload（负载）:用来存放实际需要传递的数据
3. Signature（签名）：服务器通过`Payload`、`Header`和一个密钥(`secret`)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。

![image-20200828203930497](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200828203930497.png)



### 什么是OAuth 2.0？

OAuth 是一个行业的标准授权协议，主要用来授权第三方应用获取有限的权限。

实际上它就是一种**授权机制**，它的最终目的是为第三方应用颁发一个有时效性的令牌 token，使得第三方应用能够通过该令牌获取相关的资源。

OAuth 2.0 比较常用的场景就是第三方登录，当你的网站接入了第三方登录的时候一般就是使用的 OAuth 2.0 协议。

另外，现在OAuth 2.0也常见于支付场景（微信支付、支付宝支付）和开发平台（微信开放平台、阿里开放平台等等）。

### 什么是 SSO?

SSO(Single Sign On)即单点登录说的是用户登陆多个子系统的其中一个就有权访问与其相关的其他系统。举个例子我们在登陆了京东金融之后，我们同时也成功登陆京东的京东超市、京东家电等子系统。

### 四种引用类型

- **强引用**：我们常常new出来的对象就是强引用类型，只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候
- **软引用**：使用SoftReference修饰的对象被称为软引用，软引用指向的对象在内存要溢出的时候被回收
- **弱引用**：使用WeakReference修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收
- **虚引用**：虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知

## token 的优势

避免csrf攻击

适合移动端应用

单点登录友好

### 常见问题

**注销登录还有效**：token 存入数据库，黑名单机制，修改密匙，保持令牌的有效期并经常轮换

**续签问题**：每次请求都返回新的token、token 设置到半夜、

## 分布式

### 分布式事务

简单的说，就是一次大的操作由不同的小操作组成，这些**小的操作**分布在不同的**服务器**上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。

分布式事务，本质上是对多个数据库的事务进行统一控制，按照控制力度可以分为：不控制、部分控制和完全控制。不控制就是不引入分布式事务，部分控制就是各种变种的两阶段提交，包括上面提到的消息事务+最终一致性、TCC模式，而完全控制就是完全实现两阶段提交。部分控制的好处是并发量和性能很好，缺点是数据一致性减弱了，完全控制则是牺牲了性能，保障了一致性。

**分布式系统的一致性**

### 分布式存储

**分布式存储系统将数据分散存储在多台独立的设备上**。传统的网络存储系统采用集中的存储服务器存放所有数据，存储服务器成为系统性能的瓶颈，也是可靠性和安全性的焦点，不能满足大规模存储应用的需要。分布式网络存储系统采用可扩展的系统结构，利用多台存储服务器分担存储负荷，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。

### 分布式计算

**所谓分布式计算是一门计算机科学，它研究如何把一个需要非常巨大的计算能力才能解决的问题分成许多小的部分，然后把这些部分分配给许多计算机进行处理，最后把这些计算结果综合起来得到最终的结果。** 分布式网络存储技术是将数据分散的存储于多台独立的机器设备上。分布式网络存储系统采用可扩展的系统结构，利用多台存储服务器分担存储负荷，利用位置服务器定位存储信息，不但解决了传统集中式存储系统中单存储服务器的瓶颈问题，还提高了系统的可靠性、可用性和扩展性。

## Dubbo

Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC 框架，它提供了三大核心能力：**面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现**。

**RPC**

不同的服务A，B，想要相互调用，rpc 就是负责让远程方法像本地方法一样调用

RPC 只是一种概念、一种设计，就是为了解决 **不同服务之间的调用问题**, 它一般会包含有 **传输协议**（http） 和 **序列化协议** 这两个。

![image-20200829100403053](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829100403053.png)

1. 服务消费方（client）调用以**本地调用**方式调用服务；
2. **client stub**接收到调用后负责将方法、参数等组装成能够进行网络传输的**消息体**；
3. client stub找到服务地址，并将消息发送到**服务端**；
4. server stub收到消息后**进行解码**；
5. server stub根据解码结果调用本地的服务；
6. 本地服务执行并将结果返回给server stub；
7. server stub将返回结果打包成消息并发送至消费方；
8. client stub接收到消息，并进行解码；
9. 服务消费方得到最终结果。

**Dobbo 四个特性** 

1. **负载均衡**——同一个服务部署在不同的机器时该调用那一台机器上的服务。
2. **服务调用链路生成**——随着系统的发展，服务越来越多，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。Dubbo 可以为我们解决服务之间互相是**如何调用**的。
3. **服务访问压力以及时长统计、资源调度和治理**——基于访问压力实时管理集群容量，提高**集群利用率**。
4. **服务降级**——某个服务挂掉之后**调用备用服务**。

**Dobbo 架构**

![image-20200829100417263](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829100417263.png)

- **Provider：** 暴露服务的服务提供方
- **Consumer：** 调用远程服务的服务消费方
- **Registry：** 服务注册与发现的注册中心
- **Monitor：** 统计服务的调用次数和调用时间的监控中心
- **Container：** 服务运行容器

**负载均衡的策略**

Random LoadBalance(默认，基于权重的随机负载均衡机制)

RoundRobin LoadBalance(不推荐，基于权重的轮询负载均衡机制)

 LeastActive LoadBalance(最少活跃调用数)

**dubbo 健壮性的表现**

1. **监控中心**宕掉不影响使用，只是**丢失部分采样数据**
2. **数据库**宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务
3. 注册中心对等集群，任意一台宕掉后，将自动切换到另一台
4. **注册中心**全部宕掉后，服务提供者和服务消费者**仍能通过本地缓存通讯**
5. **服务提供者**无状态，任意一台宕掉后，不影响使用
6. 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复

## 消息队列

![image-20200829112136023](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829112136023.png)

**在不使用消息队列服务器的时候，用户的请求数据直接写入数据库，在高并发的情况下数据库压力剧增，使得响应速度变慢。但是在使用消息队列之后，用户的请求数据发送给消息队列之后立即 返回，再由消息队列的消费者进程从消息队列中获取数据，异步写入数据库。由于消息队列服务器处理速度快于数据库（消息队列也比数据库有更好的伸缩性），因此响应速度得到大幅改善。**通过以上分析我们可以得出**消息队列具有很好的削峰作用的功能**——即**通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。** 

因为**用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败**。因此使用消息队列进行异步处理之后，需要**适当修改业务流程进行配合**，比如**用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功**，以免交易纠纷。这就类似我们平时手机订火车票和电影票。

**问题**

- **系统可用性降低：** 系统可用性在某种程度上降低，在加入MQ之前，你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！
- **系统复杂性提高：** 加入MQ之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！
- **一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!

**JMS（api）**

Java message service（点对点模式，发布订阅模式），允许应用程序组件基于JavaEE平台创建、发送、接收和读取消息。

**amqp（amqp）**

 AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准 **高级消息队列协议**（二进制应用层协议），是应用层协议的一个开放标准,为面向消息的中间件设计，兼容 JMS。

**kafka 的主要应用场景**

Kafka 是一个分布式流式处理平台，采用发布-订阅模式。

1. **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2. **容错的持久方式存储记录消息流**： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险·。
3. **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

**优势**

极致的性能、生态系统兼容性无可匹敌

**概念**

Producer（生产者） : 产生消息的一方。

Consumer（消费者） : 消费消息的一方。

Broker（代理） : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。

Topic（主题） : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。

Partition（分区） : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。

**Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**

1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

**Zookeeper 在 Kafka 中的作用知道吗？**

1. **Broker 注册** ：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
2. **Topic 注册** ： 在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
3. **负载均衡** ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

**Kafka 如何保证消息的消费顺序**

1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition

**Kafka 如何保证信息不丢失**

生产者丢失消息的情况：我们不能默认在调用`send`方法发送消息之后消息消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 `send` 方法发送消息实际上是异步的操作，我们可以通过 `get()`方法获取调用结果，但是这样也让它变为了同步操作

消费者丢失消息的情况：**解决办法也比较粗暴，我们手动关闭闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。**

![image-20200829205307646](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829205307646.png)

## spring cloud

**nginx 和 ribbon**

![image-20200829215039132](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829215039132.png)

![image-20200829215054417](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829215054417.png)

**ribbon 几种负载均衡算法**、

- **`RoundRobinRule`**：轮询策略。`Ribbon` 默认采用的策略。若经过一轮轮询没有找到可用的 `provider`，其最多轮询 10 轮。若最终还没有找到，则返回 `null`。
- **`RandomRule`**: 随机策略，从所有可用的 `provider` 中随机选择一个。
- **`RetryRule`**: 重试策略。先按照 `RoundRobinRule` 策略获取 `provider`，若获取失败，则在指定的时限内重试。默认的时限为 500 毫秒。

**hystrix 熔断和降级**

![image-20200829220118507](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829220118507.png)

**雪崩**：就是服务器一连串的崩溃

**熔断**： 就是服务雪崩的一种有效解决方案。当指定时间窗内的请求失败率达到设定阈值时，系统将通过 **断路器** 直接将此请求链路断开。

**降级是为了更好的用户体验，当一个方法调用异常时，通过执行另一种代码逻辑来给用户友好的回复**。这也就对应着 `Hystrix` 的 **后备处理** 模式。你可以通过设置 `fallbackMethod` 来给一个方法设置备用的代码逻辑。比如这个时候有一个热点新闻出现了，我们会推荐给用户查看详情，然后用户会通过id去查询新闻的详情，但是因为这条新闻太火了(比如最近什么*易对吧)，大量用户同时访问可能会导致系统崩溃，那么我们就进行 **服务降级** ，一些请求会做一些降级处理比如当前人数太多请稍后查看等等。











## docker

**容器**

如果需要通俗的描述容器的话，我觉得容器就是一个存放东西的地方，就像书包可以装各种文具、衣柜可以放各种衣服、鞋架可以放各种鞋子一样。我们现在所说的容器存放的东西可能更偏向于应用比如网站、程序甚至是系统环境。

**docker**

- **Docker 是世界领先的软件容器平台。**
- **对进程进行封装隔离，属于操作系统层面的虚拟化技术。** 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。
- **Docker 能够自动执行重复性任务**，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。
- **用户可以方便地创建和使用容器**，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。

**特点**

安全、标准、轻量

**容器vs虚拟机**

![image-20200829212554822](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200829212554822.png)

**基本概念**

镜像：特殊的文件系统

容器：镜像运行的实体

仓库：集中存放静态文件的地方



### jvm 调优

主要目的是保持虚拟机的稳定，而不是带来性能的大幅度提升，出现的相关问题，比如服务器运行多少小时，会产生oom，或者直接死机。又比如full gc 时间长，带来的服务暂停明显。解决办法，就是尽量让大对象在年轻代被回收，调整大对象在年前带的回收频次。

jvm 核心为调整年轻代、老年代的内存空间以及使用GC发生器的类型。在jar包所在的目录建立一个start.sh 文件，文件内容java -server -Xms4G //jvm启动时最大内存

-Xmx4G //jvm 整个堆的最大值

-Xmn2G //年轻代大小，剩下的是老年代大小

-XX:SurvivorRatio=1 // 设置Eden：s0：s1 之间的比例信息

-XX:+UseConcMarkSweepGC //回收器类型 这里是CMS，1.7 使用G1

-Dcom.sun.management.jmxremote 

-Dcom.sun.management.jmxremote.port=1100 

-Dcom.sun.management.jmxremote.authenticate=false 

-Dcom.sun.management.jmxremote.ssl=false -jar c1000k.jar&

### CMS 和G1

新生代：回收频率较高，选择新能较高的收集器

老年代：收集次数较少，应避免选择基于复制算法的回收器

垃圾收集器执行的时刻，应用程序需要暂停运行

可以串行收集，也可以并行收集

CMS:是最短回收停顿时间为目标的收集器，GC工作线程可以跟用户线程可以并发执行，以此来降低收集停顿时间的目的。作用于老年代的收集，基于标记-清除算法的，步骤分为4个步骤：初始标记‘、并发标记、重新标记、并发清除，其中的初始标记和重新标记仍然需要应用程序的暂停运行。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始阶段稍长一些，但远比并发标记的时间短。

CMS优点：只有初始标记、重新标记两次暂停，达到了近似并发的目的、并发收集

CMS缺点：cpu资源敏感、无法处理浮动垃圾、可能产生内存碎片

G1:从整体上是标记-整理算法，从局部上是基于复制的算法。意味着不会出现内存碎片，这种特征有利于长时间程序的运行，分配对象不会因为找不到空间而提前触发下一次GC，G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。过程如下：初始标记、并发标记、最终标记、筛选回收。初始标记，能直接关联到GC Root 的对象，停顿线程；并发标记，可达性分析，找出存活的对象；最终标记，停顿线程；

### 中间件

将具体业务和底层逻辑解耦的组件，java 常见的中间件有，tomcat、Weblogic、JBOSS、Coldfusion、Websphere、GlassFish

### 用户态和内核态

分为两个状态的原因是因为不让os崩溃，直接操作内核态可能会导致系统崩溃，从而建立用户态保护系统。

用户态：受限访问内存，不允许访问外围设备，占用cpu的能力、资源

内核态：可以访问内存中的所有数据，包括外围设备，硬盘，网卡，cpu

### cpu 线程进程

CPU：4核心 4线程。4核指的是物理核心（物理概念）。4线程（线程数是一个逻辑概念）

进程：是操作系统（OS）进行资源（CPU、内存、磁盘、IO、带宽等）分配的最小单位

线程：是**CPU**调度和分配的基本单位

## hash 和 b+树的优劣分析

**Hash索引定位快**

**Hash冲突问题**

**Hash索引不支持顺序和范围查询(Hash索引不支持顺序和范围查询是它最大的缺点。**

### 为什么MySQL选择B+树做索引

#### 区别

- B树的所有节点既存放 键(key) 也存放 数据(data);而B+树只有叶子节点存放 key 和 data，其他内节点只存放key。
- B树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
- B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程。

#### 优点

1、 **B+树的磁盘读写代价更低**：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。

2、**B+树的查询效率更加稳定**：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

3、**B+树更便于遍历**：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。

4、**B+树更适合基于范围的查询**：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。

#### 缺点

1. 主键不是有序递增的，导致每次插入数据产生大量的数据迁移和空间碎片；
2. 即使主键是有序递增的，大量写请求的分布仍是随机的；

### 事务

#### 事务的隔离级别

读未提交

读已提交

不可重复度

串行化

#### 事务的四大特征

原子性

隔离性

一致性

持久性

### concurrentHahshmap 1.7 和1.8

JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考

1. **JDK1.8的实现降低锁的粒度**，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
2. **JDK1.8版本的数据结构变得更加简单**，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
3. **JDK1.8使用红黑树来优化链表**，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档
4. JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点
   1. 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了
   2. JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
   3. 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据



### 排序

希尔排序：分组，分组变得越来越小

归并排序：拆分后再组合

快速排序：每次确定中轴元素

堆排序：树形结构，堆顶就是最值

计数排序：数组下标代表值，元素代表出现的次数

桶排序：元素放到桶中，桶中的元素进行排序

基数排序：先以个位数的大小来对数据进行排序，接着以十位数的大小来多数进行排序，接着以百位数的大小……，他在以某位数进行排序的时候，是用“桶”来排序的。

### innoDB 和 MyISAM

innoDB：支持事务，支持外键，聚簇索引，不保存具体行数，粒度是行锁

MyISAM：不支持事务，不支持外键，非聚簇索引，保存具体行数，粒度是表锁

### redis 

#### 五种数据类型

string hash list set zset

#### 为什么高效

1.redis是基于内存的，内存的读写速度非常快；

2.redis是单线程的，省去了很多上下文切换线程的时间； 

3.redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。

#### 持久化方式

流程：

（1）客户端向服务端发送写操作(数据在客户端的内存中)。

（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。

（3）服务端调用write这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。

（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。

（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。

RDB方式（redis database）：

RDB其实就是把数据以快照的形式保存在磁盘上。可以理解成把当前时刻的数据拍成一张照片保存下来。RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。

save 触发方式：该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止。

bgsave 触发方式：执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。

自动触发：自动触发是由我们的配置文件来完成的。

优势

（1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。

（2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。

（3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

劣势

当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。

AOF方式（Append Only File）

全量备份总是耗时的，有时候我们提供一种更加高效的方式AOF，工作机制很简单，redis会将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。

持久化原理：![image-20200822195717458](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200822195717458.png)

三种触发原理：

（1）每修改同步always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好

（2）每秒同步everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失

（3）不同no：从不同步

优点

（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。

（2）AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。

（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。

（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据

缺点

（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大

（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的

（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。

### 缓冲（buffer）和缓存（cache）

缓存（cache）是用来加速数据从硬盘中"读取"的，而缓冲（buffer）是用来加速数据"写入"硬盘的。

### 磁盘寻道算法

先来先服务

最短距离优先

电梯算法

循环扫描

### 软硬中断

软中断是执行中断指令产生的，而硬中断是由外设引发的。

硬中断的中断号是由中断控制器提供的，软中断的中断号由指令直接指出，无需使用中断控制器。

硬中断是可屏蔽的，软中断不可屏蔽。

硬中断处理程序要确保它能快速地完成任务，这样程序执行时才不会等待较长时间，称为上半部。

软中断处理硬中断未完成的工作，是一种推后执行的机制，属于下半部。 

### 红黑树和avl

1. 红黑树不追求"完全平衡"，即不像AVL那样要求节点的 `|balFact| <= 1`，
2. 就插入节点导致树失衡的情况，AVL和RB-Tree都是最多两次树旋转来实现复衡rebalance，旋转的量级是O(1)，删除节点导致失衡，AVL需要维护从被删除节点到根节点root这条路径上所有节点的平衡，旋转的量级为O(logN)
3. AVL的结构相较于RB-Tree更为平衡，插入和删除引起失衡，RB-Tree复衡效率更高；当然，由于AVL高度平衡，因此AVL的Search效率更高啦。
4. 针对插入和删除节点导致失衡后的rebalance操作，降低开销，是对search，insert ，以及delete效率的折衷，总体来说，RB-Tree的统计性能高于AVL.
5. 故引入RB-Tree是功能、性能、空间开销的折中结果。
    5.1 AVL更平衡，结构上更加直观，时间效能针对读取而言更高；维护稍慢，空间开销较大。
    5.2 红黑树，读取略逊于AVL，维护强于AVL，空间开销与AVL类似，内容极多时略优于AVL，维护优于AVL。
    基本上主要的几种平衡树看来，**红黑树有着良好的稳定性和完整的功能，性能表现也很不错，综合实力强**，在诸如STL的场景中需要稳定表现。

总结：实际应用中，若搜索的次数远远大于插入和删除，那么选择AVL，如果搜索，插入删除次数几乎差不多，应该选择RB。